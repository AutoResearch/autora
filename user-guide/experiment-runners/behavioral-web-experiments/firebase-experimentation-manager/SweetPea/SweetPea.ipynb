{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# SweetPea With Firebase\n",
    "Here we use autora to upload counterbalanced trial sequences to an experiment hosted with Firebase.\n",
    "You can find a tutorial on how to set up a firebase experiment, that is configured to work with AutoRA here:\n",
    "[Firebase Tutorial](https://github.com/AutoResearch/autora-closed-loop-firebase-tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install sweetpea\n",
    "!pip install \"autora[experiment-runner-experimentation-manager-firebase]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "First we are going to create a counterbalanced stroop trial sequence (additional tutorials on how to use SweetPea can be found here: [Tutorials](https://sites.google.com/view/sweetpea-ai))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create The Trial Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# IMPORTS:\n",
    "from sweetpea import (\n",
    "    Factor, DerivedLevel, WithinTrial,\n",
    "    CrossBlock, synthesize_trials,\n",
    "    CMSGen, MinimumTrials\n",
    ")\n",
    "\n",
    "# DEFINE COLOR AND WORD FACTORS\n",
    "color      = Factor(\"color\",  [\"red\", \"blue\", \"green\", \"brown\"])\n",
    "word       = Factor(\"word\", [\"red\", \"blue\", \"green\", \"brown\"])\n",
    "\n",
    "# DEFINE CONGRUENCY FACTOR\n",
    "\n",
    "def congruent(color, word):\n",
    "    return color == word\n",
    "\n",
    "def incongruent(color, word):\n",
    "    return not congruent(color, word)\n",
    "\n",
    "\n",
    "conLevel = DerivedLevel(\"con\", WithinTrial(congruent,   [color, word]))\n",
    "incLevel = DerivedLevel(\"inc\", WithinTrial(incongruent,   [color, word]))\n",
    "\n",
    "congruency = Factor(\"congruency\", [\n",
    "    conLevel,\n",
    "    incLevel\n",
    "])\n",
    "\n",
    "# DEFINE EXPERIMENT\n",
    "design       = [color, word, congruency]\n",
    "crossing     = [congruency]\n",
    "block        = CrossBlock(design, crossing, [MinimumTrials(48)])\n",
    "\n",
    "# SYNTHESIZE 5 TRIAL SEQUENCES\n",
    "\n",
    "experiments  = synthesize_trials(block, 5, CMSGen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's see, what the experiment object is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('All sequences:')\n",
    "print(experiments)\n",
    "print('One sequence:')\n",
    "print(experiments[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For the firebase experiments, it is more convenient to have lists of trials instead of feature list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "firebase_formatted = []\n",
    "for el in experiments:\n",
    "    trials = []\n",
    "    for color, word, congruency in zip(el[\"color\"], el[\"word\"], el[\"congruency\"]):\n",
    "        trial = {\"color\": color, \"word\": word, \"congruency\": congruency}\n",
    "        trials.append(trial)\n",
    "    firebase_formatted.append(trials)\n",
    "print(firebase_formatted[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Upload To Firebase\n",
    "Let's import the send_condition from the experimentation_manager and see what arguments are expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from autora.experiment_runner.experimentation_manager.firebase import send_conditions\n",
    "help(send_conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "collection_name: is a name that we choose (here we choose autora)\n",
    "conditions: the conditions (in this case the trial sequences)\n",
    "firebase_credentials: a dict with the credentials for firebase (found here: [Firebase](https://console.firebase.google.com/) under project-settings -> service accounts -> generate key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collection_name = 'autora'\n",
    "conditions = firebase_formatted\n",
    "firebase_credentials = {\n",
    "  \"type\": \"\",\n",
    "  \"project_id\": \"\",\n",
    "  \"private_key_id\": \"\",\n",
    "  \"private_key\": \"\",\n",
    "  \"client_email\": \"\",\n",
    "  \"client_id\": \"\",\n",
    "  \"auth_uri\": \"\",\n",
    "  \"token_uri\": \"\",\n",
    "  \"auth_provider_x509_cert_url\": \"\",\n",
    "  \"client_x509_cert_url\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "send_conditions(collection_name=collection_name, conditions=conditions, firebase_credentials=firebase_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Check out your [Firebase](https://console.firebase.google.com/) in the browser. The conditions were added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Check Firebase Status\n",
    "To check the status of the experiment you can use the function `check_status` (this is helpful to build a closed loop, where a `autora-recruitment-manager` starts and pauses the recruitment based on the status of the experiment, while the `autora-experimentation-manager` retrieves the observations and sends new conditions from the `autora-experimentalist` when data-collection is finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from autora.experiment_runner.experimentation_manager.firebase import check_firebase_status\n",
    "\n",
    "status = check_firebase_status(collection_name=collection_name, firebase_credentials=firebase_credentials, time_out=100)\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This gives you a string (unavailable, available or finished):\n",
    "- If all conditions are in use but not finished the function returns `unavailable` (the time_out governs how long a participant is allowed to take part in the experiment till the condition gets freed for the next user)\n",
    "- If there are available spots (meaning there are conditions not started yet or there are conditions that have been timed out), the function returns `available`\n",
    "- If all conditions are used and the data for these conditions has been collected, the function returns `finished`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Get Observations\n",
    "To download the observations from the Firestore databse, we can use the `get_observations` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from autora.experiment_runner.experimentation_manager.firebase import get_observations\n",
    "\n",
    "observations = get_observations(collection_name=collection_name, firebase_credentials=firebase_credentials)\n",
    "print(observations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
