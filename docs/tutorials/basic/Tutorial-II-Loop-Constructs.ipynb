{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "## Basic Tutorial II: Loop Constructs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[AutoRA](https://pypi.org/project/autora/)** (**Au**tomated **R**esearch **A**ssistant) is an open-source framework designed to automate various stages of empirical research, including model discovery, experimental design, and data collection.\n",
    "\n",
    "This notebook is the second of four notebooks within the basic tutorials of ``autora``. We suggest that you go through these notebooks in order as each builds upon the last. However, each notebook is self-contained and so there is no need to *run* the content of the last notebook for your current notebook. We will here provide a link to each notebook, but we will also provide a link at the end of each notebook to navigate you to the next notebook.\n",
    "\n",
    "[AutoRA Basic Tutorial I: Components](https://autoresearch.github.io/autora/tutorials/basic/Tutorial-I-Components/) <br>\n",
    "[AutoRA Basic Tutorial II: Loop Constructs](https://autoresearch.github.io/autora/tutorials/basic/Tutorial-II-Loop-Constructs/) <br>\n",
    "[AutoRA Basic Tutorial III: Functional Workflow](https://autoresearch.github.io/autora/tutorials/basic/Tutorial-III-Functional-Workflow/) <br>\n",
    "[AutoRA Basic Tutorial IV: Customization](https://autoresearch.github.io/autora/tutorials/basic/Tutorial-IV-Customization/) <br>\n",
    "\n",
    "These notebooks provide a comprehensive introduction to the capabilities of ``autora``. **It demonstrates the fundamental components of ``autora``, and how they can be combined to facilitate automated (closed-loop) empirical research through synthetic experiments.**\n",
    "\n",
    "**How to use this notebook** *You can progress through the notebook section by section or directly navigate to specific sections. If you choose the latter, it is recommended to execute all cells in the notebook initially, allowing you to easily rerun the cells in each section later without issues.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Setup\n",
    "This tutorial is self-contained so that you do not need to run the previous notebook to begin. However, the four notebooks are continuous so that what we define in a previous notebook should still exist within this notebook. As such, we will here re-run relevant code from past tutorials. We will not again walk you through these, but if you need a reminder what they are then go see the descriptions in previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Installation ####\n",
    "!pip install -q \"autora[experimentalist-falsification]\"\n",
    "!pip install -q \"autora[experimentalist-sampler-model-disagreement]\"\n",
    "!pip install -q \"autora[theorist-bms]\"\n",
    "\n",
    "#### Import modules ####\n",
    "import numpy as np\n",
    "import torch\n",
    "from autora.variable import Variable, ValueType, VariableCollection\n",
    "from autora.experimentalist.pooler.random_pooler import random_pool\n",
    "from autora.experimentalist.sampler.falsification import falsification_sample\n",
    "from autora.experimentalist.sampler.model_disagreement import model_disagreement_sample\n",
    "from autora.theorist.bms import BMSRegressor\n",
    "from sklearn import linear_model\n",
    "\n",
    "#### Set seeds ####\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "#### Define ground truth and experiment runner ####\n",
    "ground_truth = lambda x: np.sin(x)\n",
    "run_experiment = lambda x: ground_truth(x) + np.random.normal(0, 0.1, size=x.shape)\n",
    "\n",
    "#### Define condition pool ####\n",
    "condition_pool = np.linspace(0, 2 * np.pi, 100)\n",
    "condition_pool = condition_pool.reshape((len(condition_pool), 1))\n",
    "\n",
    "#### Define metadata ####\n",
    "iv = Variable(name=\"x\", value_range=(0, 2 * np.pi), allowed_values=condition_pool)\n",
    "dv = Variable(name=\"y\", type=ValueType.REAL)\n",
    "metadata = VariableCollection(independent_variables=[iv],dependent_variables=[dv])\n",
    "\n",
    "#### Define theorists ####\n",
    "theorist_lr = linear_model.LinearRegression()\n",
    "theorist_bms = BMSRegressor(epochs=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop Constructs\n",
    "After defining all the components required for the empirical research process, we can create an automated workflow using basic loop constructs in Python.\n",
    "\n",
    "The following code block demonstrates how to build such a workflow using the components introduced in the preceding notebook, such as\n",
    "\n",
    "- ``metadata`` (object specifying variables of the experiment), <br>\n",
    "- ``run_experiment`` (function for collecting data), <br>\n",
    "- ``theorist_bms`` (scikit learn estimator for discoverying equations using the Bayesian Machine Scientist), <br>\n",
    "- ``random_pool`` (function for generating a random pool of experimental conditions), and <br>\n",
    "- ``falsification_sample`` (function for identifying novel experiment conditions using the falsification .sampler) <br>\n",
    "\n",
    "We begin with implementing the following workflow:\n",
    "1. Generate 3 seed experimental conditions using ``random_pool``\n",
    "2. Generate 3 seed observations using ``run_experiment``\n",
    "3. Loop through the following steps 5 times\n",
    "   - Identify a model relating conditions to observations using ``theorist_bms``\n",
    "   - Identify 3 new experimental conditions using ``falsification_sample``\n",
    "   - Collect 3 new observations using ``run_experiment``\n",
    "   - Add new conditions and observations to the dataset\n",
    "\n",
    "We will here begin using the naming convention ``cycle`` to refer to an entire AutoRA loop where the loop encounters all AutoRA components - experiment runner, theorist, experimentalist. Within the scientific method, a cycle would then be running a single iteration of the experiment. This requires the collection of data, the modelling of that data, and the conceptualization of the next iteration of this experiment. For example, if our research concerns how much information a person acquires from a photo (dependent variable) dependent on how bright the photo is (independent variable), we may first collect data with conditions of (let's say) 10%, 50%, and 90% brightness, then model our collected data to determine the relationship between brightness and photo perception, and finally determine which other brightness conditions may help us understand the true relationship. Probing other conditions - such as a brightness of 25% and of 75% would then be the next iteration of the experiment and thus, for us, the next cycle. The following code block will iterate through five of these cycles."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Falsification Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autora.theorist.bms.regressor:BMS fitting started\n",
      "100%|██████████| 100/100 [00:03<00:00, 27.81it/s]\n",
      "INFO:autora.theorist.bms.regressor:BMS fitting finished\n",
      "WARNING:autora.utils.deprecation:Use `falsification_score_sample_from_predictions` instead. `falsification_score_sampler_from_predictions` is deprecated.\n",
      "INFO:autora.theorist.bms.regressor:BMS fitting started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in cycle 0: 0.0\n",
      "Discovered Model: sin(X0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 27.69it/s]\n",
      "INFO:autora.theorist.bms.regressor:BMS fitting finished\n",
      "WARNING:autora.utils.deprecation:Use `falsification_score_sample_from_predictions` instead. `falsification_score_sampler_from_predictions` is deprecated.\n",
      "INFO:autora.theorist.bms.regressor:BMS fitting started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in cycle 1: 0.0\n",
      "Discovered Model: sin(X0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 24.21it/s]\n",
      "INFO:autora.theorist.bms.regressor:BMS fitting finished\n",
      "WARNING:autora.utils.deprecation:Use `falsification_score_sample_from_predictions` instead. `falsification_score_sampler_from_predictions` is deprecated.\n",
      "INFO:autora.theorist.bms.regressor:BMS fitting started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in cycle 2: 0.0\n",
      "Discovered Model: sin(X0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 26.50it/s]\n",
      "INFO:autora.theorist.bms.regressor:BMS fitting finished\n",
      "WARNING:autora.utils.deprecation:Use `falsification_score_sample_from_predictions` instead. `falsification_score_sampler_from_predictions` is deprecated.\n",
      "INFO:autora.theorist.bms.regressor:BMS fitting started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in cycle 3: 0.0\n",
      "Discovered Model: sin(X0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 26.33it/s]\n",
      "INFO:autora.theorist.bms.regressor:BMS fitting finished\n",
      "WARNING:autora.utils.deprecation:Use `falsification_score_sample_from_predictions` instead. `falsification_score_sampler_from_predictions` is deprecated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in cycle 4: 0.0\n",
      "Discovered Model: sin(X0)\n"
     ]
    }
   ],
   "source": [
    "num_cycles = 5 # number of empirical research cycles\n",
    "measurements_per_cycle = 3 # number of data points to collect for each cycle\n",
    "\n",
    "# generate an initial set of experimental conditions\n",
    "conditions = random_pool(metadata.independent_variables,\n",
    "                                 num_samples=measurements_per_cycle)\n",
    "\n",
    "# convert iterator into 2-dimensional numpy array\n",
    "conditions = np.array(list(conditions)).reshape(-1, 1)\n",
    "\n",
    "# collect initial set of observations\n",
    "observations = run_experiment(conditions)\n",
    "\n",
    "for cycle in range(num_cycles):\n",
    "\n",
    "  # use BMS theorist to fit the model to the data\n",
    "  theorist_bms.fit(conditions, observations)\n",
    "\n",
    "  # obtain new conditions\n",
    "  new_conditions = falsification_sample(\n",
    "          condition_pool=condition_pool,\n",
    "          model=theorist_bms,\n",
    "          reference_conditions=conditions,\n",
    "          reference_observations=observations,\n",
    "          metadata=metadata,\n",
    "          num_samples=measurements_per_cycle,\n",
    "      )\n",
    "\n",
    "  # obtain new observations\n",
    "  new_observations = run_experiment(new_conditions)\n",
    "\n",
    "  # combine old and new conditions and observations\n",
    "  conditions = np.concatenate((conditions, new_conditions))\n",
    "  observations = np.concatenate((observations, new_observations))\n",
    "\n",
    "  # evaluate model of the theorist based on its ability to predict each observation from the ground truth, evaluated across the entire space of experimental conditions\n",
    "  loss = np.mean(np.square(theorist_bms.predict(condition_pool) - ground_truth(condition_pool)))\n",
    "  print(\"Loss in cycle {}: {}\".format(cycle, loss))\n",
    "  print(\"Discovered Model: \" +  theorist_bms.repr())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Model Disagreement Sampler\n",
    "We can easily replace components in the workflow above. For instance, we could replace  ``falsification_sample`` with the ``experimentalist_pipeline`` defined in Tutorial I.\n",
    "\n",
    "In the following code block, we add a linear regression theorist, to fit a linear model to the data. In addition, we replace ``falsification_sample`` with  ``model_disagreement_sample`` to sample experimental conditions that differentiate most between the linear model and the model discovered by the BMS theorist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autora.theorist.bms.regressor:BMS fitting started\n",
      "100%|██████████| 100/100 [00:04<00:00, 23.59it/s]\n",
      "INFO:autora.theorist.bms.regressor:BMS fitting finished\n",
      "INFO:autora.theorist.bms.regressor:BMS fitting started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in cycle 0: 0.0\n",
      "Discovered BMS Model: sin(X0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 26.18it/s]\n",
      "INFO:autora.theorist.bms.regressor:BMS fitting finished\n",
      "INFO:autora.theorist.bms.regressor:BMS fitting started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in cycle 1: 0.0\n",
      "Discovered BMS Model: sin(X0)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 16\u001b[0m\n\u001b[0;32m     11\u001b[0m observations \u001b[39m=\u001b[39m run_experiment(conditions)\n\u001b[0;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m cycle \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_cycles):\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m   \u001b[39m# use BMS theorist to fit the model to the data\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m   theorist_bms\u001b[39m.\u001b[39;49mfit(conditions, observations)\n\u001b[0;32m     17\u001b[0m   theorist_lr\u001b[39m.\u001b[39mfit(conditions, observations)\n\u001b[0;32m     19\u001b[0m   \u001b[39m# obtain new conditions\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cwill\\GitHub\\virtualEnvs\\autoraEnv\\lib\\site-packages\\autora\\theorist\\bms\\regressor.py:133\u001b[0m, in \u001b[0;36mBMSRegressor.fit\u001b[1;34m(self, X, y, num_param, root, custom_ops, seed)\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_primitive(root)\n\u001b[0;32m    121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpms \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    122\u001b[0m     Ts\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mts,\n\u001b[0;32m    123\u001b[0m     variables\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariables,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    131\u001b[0m     seed\u001b[39m=\u001b[39mseed,\n\u001b[0;32m    132\u001b[0m )\n\u001b[1;32m--> 133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache_ \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpms, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepochs)\n\u001b[0;32m    134\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodels_ \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpms\u001b[39m.\u001b[39mtrees\u001b[39m.\u001b[39mvalues())\n\u001b[0;32m    136\u001b[0m _logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mBMS fitting finished\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\cwill\\GitHub\\virtualEnvs\\autoraEnv\\lib\\site-packages\\autora\\theorist\\bms\\utils.py:34\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(pms, num_steps, thinning)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \n\u001b[0;32m     32\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     33\u001b[0m desc_len, model, model_len \u001b[39m=\u001b[39m [], pms\u001b[39m.\u001b[39mt1, np\u001b[39m.\u001b[39minf\n\u001b[1;32m---> 34\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39;49m(num_steps)):\n\u001b[0;32m     35\u001b[0m     pms\u001b[39m.\u001b[39mmcmc_step()\n\u001b[0;32m     36\u001b[0m     pms\u001b[39m.\u001b[39mtree_swap()\n",
      "File \u001b[1;32mc:\\Users\\cwill\\GitHub\\virtualEnvs\\autoraEnv\\lib\\site-packages\\tqdm\\std.py:1093\u001b[0m, in \u001b[0;36mtqdm.__init__\u001b[1;34m(self, iterable, desc, total, leave, file, ncols, mininterval, maxinterval, miniters, ascii, disable, unit, unit_scale, dynamic_ncols, smoothing, bar_format, initial, position, postfix, unit_divisor, write_bytes, lock_args, nrows, colour, delay, gui, **kwargs)\u001b[0m\n\u001b[0;32m   1089\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_free_pos(\u001b[39mself\u001b[39m) \u001b[39mif\u001b[39;00m position \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m-\u001b[39mposition\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m gui:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# Initialize the screen printer\u001b[39;00m\n\u001b[1;32m-> 1093\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstatus_printer(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp)\n\u001b[0;32m   1094\u001b[0m     \u001b[39mif\u001b[39;00m delay \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1095\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrefresh(lock_args\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlock_args)\n",
      "File \u001b[1;32mc:\\Users\\cwill\\GitHub\\virtualEnvs\\autoraEnv\\lib\\site-packages\\tqdm\\std.py:336\u001b[0m, in \u001b[0;36mtqdm.status_printer\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m    334\u001b[0m fp_flush \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(fp, \u001b[39m'\u001b[39m\u001b[39mflush\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlambda\u001b[39;00m: \u001b[39mNone\u001b[39;00m)  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \u001b[39mif\u001b[39;00m fp \u001b[39min\u001b[39;00m (sys\u001b[39m.\u001b[39mstderr, sys\u001b[39m.\u001b[39mstdout):\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mgetattr\u001b[39;49m(sys\u001b[39m.\u001b[39;49mstderr, \u001b[39m'\u001b[39;49m\u001b[39mflush\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mlambda\u001b[39;49;00m: \u001b[39mNone\u001b[39;49;00m)()\n\u001b[0;32m    337\u001b[0m     \u001b[39mgetattr\u001b[39m(sys\u001b[39m.\u001b[39mstdout, \u001b[39m'\u001b[39m\u001b[39mflush\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlambda\u001b[39;00m: \u001b[39mNone\u001b[39;00m)()\n\u001b[0;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfp_write\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\cwill\\GitHub\\virtualEnvs\\autoraEnv\\lib\\site-packages\\ipykernel\\iostream.py:559\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"trigger actual zmq send\u001b[39;00m\n\u001b[0;32m    549\u001b[0m \n\u001b[0;32m    550\u001b[0m \u001b[39msend will happen in the background thread\u001b[39;00m\n\u001b[0;32m    551\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    552\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    553\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpub_thread\n\u001b[0;32m    554\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpub_thread\u001b[39m.\u001b[39mthread \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    557\u001b[0m ):\n\u001b[0;32m    558\u001b[0m     \u001b[39m# request flush on the background thread\u001b[39;00m\n\u001b[1;32m--> 559\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpub_thread\u001b[39m.\u001b[39;49mschedule(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flush)\n\u001b[0;32m    560\u001b[0m     \u001b[39m# wait for flush to actually get through, if we can.\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     evt \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mEvent()\n",
      "File \u001b[1;32mc:\\Users\\cwill\\GitHub\\virtualEnvs\\autoraEnv\\lib\\site-packages\\ipykernel\\iostream.py:251\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_events\u001b[39m.\u001b[39mappend(f)\n\u001b[0;32m    250\u001b[0m     \u001b[39m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event_pipe\u001b[39m.\u001b[39;49msend(\u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    252\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     f()\n",
      "File \u001b[1;32mc:\\Users\\cwill\\GitHub\\virtualEnvs\\autoraEnv\\lib\\site-packages\\zmq\\sugar\\socket.py:696\u001b[0m, in \u001b[0;36mSocket.send\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    689\u001b[0m         data \u001b[39m=\u001b[39m zmq\u001b[39m.\u001b[39mFrame(\n\u001b[0;32m    690\u001b[0m             data,\n\u001b[0;32m    691\u001b[0m             track\u001b[39m=\u001b[39mtrack,\n\u001b[0;32m    692\u001b[0m             copy\u001b[39m=\u001b[39mcopy \u001b[39mor\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    693\u001b[0m             copy_threshold\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy_threshold,\n\u001b[0;32m    694\u001b[0m         )\n\u001b[0;32m    695\u001b[0m     data\u001b[39m.\u001b[39mgroup \u001b[39m=\u001b[39m group\n\u001b[1;32m--> 696\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msend(data, flags\u001b[39m=\u001b[39;49mflags, copy\u001b[39m=\u001b[39;49mcopy, track\u001b[39m=\u001b[39;49mtrack)\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:742\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:789\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:250\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\cwill\\GitHub\\virtualEnvs\\autoraEnv\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_cycles = 5 # number of empirical research cycles\n",
    "measurements_per_cycle = 3 # number of data points to collect for each cycle\n",
    "\n",
    "# generate an initial set of experimental conditions\n",
    "conditions = random_pool(metadata.independent_variables,\n",
    "                                 num_samples=measurements_per_cycle)\n",
    "# convert iterator into 2-dimensional numpy array\n",
    "conditions = np.array(list(conditions)).reshape(-1, 1)\n",
    "\n",
    "# collect initial set of observations\n",
    "observations = run_experiment(conditions)\n",
    "\n",
    "for cycle in range(num_cycles):\n",
    "\n",
    "  # use BMS theorist to fit the model to the data\n",
    "  theorist_bms.fit(conditions, observations)\n",
    "  theorist_lr.fit(conditions, observations)\n",
    "\n",
    "  # obtain new conditions\n",
    "  new_conditions = model_disagreement_sample(\n",
    "          condition_pool,\n",
    "          models = [theorist_bms, theorist_lr],\n",
    "          num_samples = measurements_per_cycle\n",
    "      )\n",
    "\n",
    "  # obtain new observations\n",
    "  new_observations = run_experiment(new_conditions)\n",
    "\n",
    "  # combine old and new conditions and observations\n",
    "  conditions = np.concatenate((conditions, new_conditions))\n",
    "  observations = np.concatenate((observations, new_observations))\n",
    "\n",
    "  # evaluate model of the theorist based on its ability to predict each observation from the ground truth, evaluated across the entire space of experimental conditions\n",
    "  loss = np.mean(np.square(theorist_bms.predict(condition_pool) - ground_truth(condition_pool)))\n",
    "  print(\"Loss in cycle {}: {}\".format(cycle, loss))\n",
    "  print(\"Discovered BMS Model: \" +  theorist_bms.repr())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Notebook\n",
    "While the basic loop construct is flexible, there are more convenient ways to specify a research cycle in ``autora``. The next notebook illustrates the use of these constructs.\n",
    "\n",
    "Follow this link for the next notebook tutorial:\n",
    "[AutoRA Basic Tutorial III: Functional Workflow](https://autoresearch.github.io/autora/tutorials/basic/Tutorial-III-Workflow-Logic/) <br>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "autoraKernel",
   "language": "python",
   "name": "autorakernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
