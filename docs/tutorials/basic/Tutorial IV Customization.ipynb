{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial IV Customization\n",
    "## Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[AutoRA](https://pypi.org/project/autora/)** (**Au**tomated **R**esearch **A**ssistant) is an open-source framework designed to automate various stages of empirical research, including model discovery, experimental design, and data collection.\n",
    "\n",
    "This notebook is the fourth of four notebooks within the basic tutorials of ``autora``. We suggest that you go through these notebooks in order as each builds upon the last. However, each notebook is self-contained and so there is no need to *run* the content of the last notebook for your current notebook. \n",
    "\n",
    "These notebooks provide a comprehensive introduction to the capabilities of ``autora``. **It demonstrates the fundamental components of ``autora``, and how they can be combined to facilitate automated (closed-loop) empirical research through synthetic experiments.**\n",
    "\n",
    "**How to use this notebook** *You can progress through the notebook section by section or directly navigate to specific sections. If you choose the latter, it is recommended to execute all cells in the notebook initially, allowing you to easily rerun the cells in each section later without issues.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial Setup\n",
    "\n",
    "We will here import some standard python packages, set seeds for replicability, and define a plotting function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Installation ####\n",
    "!pip install -q \"autora[theorist-bms]\"\n",
    "!pip install -q \"autora[experiment-runner-synthetic-abstract-equation]\"\n",
    "\n",
    "#### Import modules ####\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy as sp\n",
    "import torch\n",
    "\n",
    "from autora.variable import Variable, ValueType, VariableCollection\n",
    "from autora.state import StandardState, on_state, estimator_on_state\n",
    "from autora.experimentalist.random import random_pool\n",
    "from autora.theorist.bms import BMSRegressor\n",
    "from autora.experiment_runner.synthetic.abstract.equation import equation_experiment\n",
    "\n",
    "#### Set seeds ####\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "#### Define plot function ####\n",
    "def plot_from_state(s: StandardState, expr: str):    \n",
    "    \n",
    "    \"\"\"\n",
    "    Plots the data, the ground truth model, and the current predicted model\n",
    "    \"\"\"\n",
    "    \n",
    "    #Determine labels and variables\n",
    "    print(s.models[-1])\n",
    "    model_label = f\"Model: {s.models[-1]}\" if hasattr(s.models[-1],'repr') else \"Model\"\n",
    "    experiment_data = s.experiment_data.sort_values(by=[\"x\"])\n",
    "    ground_x = np.linspace(s.variables.independent_variables[0].value_range[0],s.variables.independent_variables[0].value_range[1],100)\n",
    "    \n",
    "    #Determine predicted ground truth\n",
    "    equation = sp.simplify(expr)\n",
    "    ground_predicted_y = [equation.evalf(subs={'x':x}) for x in ground_x]\n",
    "    model_predicted_y = s.models[-1].predict(ground_x.reshape(-1, 1))\n",
    "\n",
    "    #Plot the data and models\n",
    "    f = plt.figure(figsize=(4,3))\n",
    "    plt.plot(experiment_data[\"x\"], experiment_data[\"y\"], 'o', label = None)\n",
    "    plt.plot(ground_x, model_predicted_y, alpha=.8, label=model_label)\n",
    "    plt.plot(ground_x, ground_predicted_y, alpha=.8,  label=f'Ground Truth: {expr}')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing Automated Empirical Research Components\n",
    "\n",
    "``autora`` is a flexible framework in which users can integrate their own experimentalists, experiment runners, and theorists in an automated empirical research workflow. This section illustrates the integration of custom `autora` components. For more information on how to contribute your own modules to the ``autora`` ecosystem, please refer to the [Contributor Documentation](https://autoresearch.github.io/autora/contribute/modules/).\n",
    "\n",
    "To illustrate the use of custom experimentalists, experiment runners, and theorists, we consider a simple workflow:\n",
    "1. Generate 10 seed experimental conditions using `random_pool`\n",
    "2. Iterate through the following steps\n",
    "   - Identify 3 new experimental conditions using an ``experimentalist``\n",
    "   - Collect observations using the ``experiment_runner``\n",
    "   - Identify a model relating conditions to observations using a ``theorist``\n",
    "\n",
    "Once this workflow is setup, we will replace each component with a custom function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define metadata ####\n",
    "iv = Variable(name=\"x\", value_range=(0, 2 * np.pi), allowed_values=np.linspace(0, 2 * np.pi, 30))\n",
    "dv = Variable(name=\"y\", type=ValueType.REAL)\n",
    "variables = VariableCollection(independent_variables=[iv],dependent_variables=[dv])\n",
    "\n",
    "#### Define condition pool ####\n",
    "conditions = random_pool(variables, num_samples=10, random_state=0)\n",
    "\n",
    "#### Define state ####\n",
    "s = StandardState(\n",
    "    variables = variables,\n",
    "    conditions = conditions,\n",
    "    experiment_data = pd.DataFrame(columns=[\"x\",\"y\"])\n",
    ")\n",
    "\n",
    "#### Define experimentalist and wrap with state functionality ####\n",
    "experimentalist = on_state(random_pool, output=[\"conditions\"])\n",
    "\n",
    "#### Define experiment runner and wrap with state functionality ####\n",
    "sin_experiment = equation_experiment(sp.simplify('sin(x)'), variables.independent_variables, variables.dependent_variables[0])\n",
    "sin_runner = sin_experiment.run\n",
    "\n",
    "experiment_runner = on_state(sin_runner, output=[\"experiment_data\"])\n",
    "\n",
    "#### Define theorist and wrap with state functionality ####\n",
    "theorist = estimator_on_state(BMSRegressor(epochs=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should quickly test to make sure everything works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\033[1mPrevious State:\\033[0m')\n",
    "print(s)\n",
    "\n",
    "for cycle in range(2):\n",
    "    s = experimentalist(s, num_samples=10, random_state=42+cycle)\n",
    "    s = experiment_runner(s, added_noise=0.5, random_state=42+cycle)\n",
    "    s = theorist(s)\n",
    "    \n",
    "    plot_from_state(s, 'sin(x)')\n",
    "\n",
    "print('\\n\\033[1mUpdated State:\\033[0m')\n",
    "print(s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Experimentalists\n",
    "\n",
    "Experimentalists must be implemented as functions. For instance, an experimentalist sampler function expects a pool of experimental conditions and returns a modified set of experimental conditions. \n",
    "\n",
    "**Requirements for working with the state:**\n",
    "- The function has a `variables` argument that accepts the `VariableCollection` type\n",
    "- The function has a `conditions` argument that accepts a `pandas.DataFrame`\n",
    "- The function returns a `pandas.DataFrame`\n",
    "\n",
    "The custom `uniform_sampler` below will select conditions that are the least represented in the data. \n",
    "\n",
    "*Note that when building custom experimentalists, we can either wrap the function with `on_state(output=['conditions'])` as we did in tutorial III, or else we can use the `@on_state(output=['conditions'])` decorator.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================================================#\n",
    "#                 Option 1 - Wrapping our Component                #\n",
    "#==================================================================#\n",
    "\n",
    "def uniform_sample(variables: VariableCollection, conditions: pd.DataFrame, num_samples: int = 1, random_state: Optional [int] = None):\n",
    "\n",
    "    \"\"\"\n",
    "    An experimentalist that selects the least represented datapoints\n",
    "    \"\"\"\n",
    "    #Set rng seed\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    #Retrieve the possible values\n",
    "    allowed_values = variables.independent_variables[0].allowed_values\n",
    "    \n",
    "    #Determine the representation of each value\n",
    "    conditions_count = np.array([conditions[\"x\"].isin([value]).sum(axis=0) for value in allowed_values])\n",
    "    \n",
    "    #Sort to determine the least represented values\n",
    "    conditions_sort = conditions_count.argsort()\n",
    "    \n",
    "    conditions_count = conditions_count[conditions_sort]\n",
    "    values_count = allowed_values[conditions_sort]\n",
    "    \n",
    "    #Sample from values with the smallest frequency\n",
    "    x = values_count[conditions_count<=conditions_count[num_samples-1]]\n",
    "    x = rng.choice(x,num_samples)\n",
    "    \n",
    "    return pd.DataFrame({\"x\": x})\n",
    "\n",
    "custom_experimentalist = on_state(uniform_sample, output=[\"conditions\"])\n",
    "\n",
    "#==================================================================#\n",
    "#                   Option 2 - Using a Decorator                   #\n",
    "#==================================================================#\n",
    "\n",
    "@on_state(output=[\"conditions\"])\n",
    "def custom_experimentalist(variables: VariableCollection, conditions: pd.DataFrame, num_samples: int = 1, random_state: Optional [int] = None):\n",
    "\n",
    "    \"\"\"\n",
    "    An experimentalist that selects the least represented datapoints\n",
    "    \"\"\"\n",
    "    #Set rng seed\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    #Retrieve the possible values\n",
    "    allowed_values = variables.independent_variables[0].allowed_values\n",
    "    \n",
    "    #Determine the representation of each value\n",
    "    conditions_count = np.array([conditions[\"x\"].isin([value]).sum(axis=0) for value in allowed_values])\n",
    "    \n",
    "    #Sort to determine the least represented values\n",
    "    conditions_sort = conditions_count.argsort()\n",
    "    \n",
    "    conditions_count = conditions_count[conditions_sort]\n",
    "    values_count = allowed_values[conditions_sort]\n",
    "    \n",
    "    #Sample from values with the smallest frequency\n",
    "    x = values_count[conditions_count<=conditions_count[num_samples-1]]\n",
    "    x = rng.choice(x,num_samples)\n",
    "    \n",
    "    return pd.DataFrame({\"x\": x})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will re-run our initial workflow while incorporating our custom experimentalist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### First, let's reinitialize the state object to get a clean state ####\n",
    "iv = Variable(name=\"x\", value_range=(0, 2 * np.pi), allowed_values=np.linspace(0, 2 * np.pi, 30))\n",
    "dv = Variable(name=\"y\", type=ValueType.REAL)\n",
    "variables = VariableCollection(independent_variables=[iv],dependent_variables=[dv])\n",
    "\n",
    "conditions = random_pool(variables, num_samples=10, random_state=0)\n",
    "\n",
    "s = StandardState(variables = variables, conditions = conditions, experiment_data = pd.DataFrame(columns=[\"x\",\"y\"]))\n",
    "\n",
    "#Report previous state\n",
    "print('\\033[1mPrevious State:\\033[0m')\n",
    "print(s)\n",
    "\n",
    "#Cycle\n",
    "for cycle in range(5):\n",
    "    s = custom_experimentalist(s, num_samples = 10, random_state=42+cycle) #Our custom experimentalist\n",
    "    s = experiment_runner(s, added_noise=0.5, random_state=42+cycle)\n",
    "    s = theorist(s)\n",
    "    \n",
    "    plot_from_state(s,'sin(x)')\n",
    "\n",
    "#Report updated state\n",
    "print('\\n\\033[1mUpdated State:\\033[0m')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Experiment Runner\n",
    "\n",
    "Experiment runners must be implemented as functions. \n",
    "\n",
    "**Requirements for working with the state:**\n",
    "- The function has a `conditions` argument that accepts a `pandas.DataFrame`\n",
    "- The function returns a `pandas.DataFrame`\n",
    "\n",
    "The custom `quadratic_experiment` below will apply a quadratic transform (`x + x**2`) to the conditions.\n",
    "\n",
    "*Note that when building custom experiment runners, we can either wrap the function with `on_state(output=['experiment_data'])` as we did in tutorial III, or else we can use the `@on_state(output=['experiment_data'])` decorator.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================================================#\n",
    "#                 Option 1 - Wrapping our Component                #\n",
    "#==================================================================#\n",
    "\n",
    "def quadratic_experiment(conditions: pd.DataFrame, added_noise: int = 0.01, random_state: Optional[int] = None):\n",
    "    \n",
    "    #Set rng seed\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    \n",
    "    #Extract conditions\n",
    "    x = conditions[\"x\"]\n",
    "    \n",
    "    #Compute data\n",
    "    y = (x + x**2) + rng.normal(0, added_noise, size=x.shape)\n",
    "    \n",
    "    #Assign to dataframe\n",
    "    observations = conditions.assign(y = y)\n",
    "    \n",
    "    return observations\n",
    "\n",
    "custom_experiment_runner = on_state(quadratic_experiment, output=[\"experiment_data\"])\n",
    "\n",
    "#==================================================================#\n",
    "#                   Option 2 - Using a Decorator                   #\n",
    "#==================================================================#\n",
    "\n",
    "@on_state(output=[\"experiment_data\"])\n",
    "def quadratic_experiment(conditions: pd.DataFrame, added_noise: int = 0.01, random_state: Optional[int] = None):\n",
    "    \n",
    "    #Set rng seed\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    \n",
    "    #Extract conditions\n",
    "    x = conditions[\"x\"]\n",
    "    \n",
    "    #Compute data\n",
    "    y = (x + x**2) + rng.normal(0, added_noise, size=x.shape)\n",
    "    \n",
    "    #Assign to dataframe\n",
    "    observations = conditions.assign(y = y)\n",
    "    \n",
    "    return observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will re-run our initial workflow while incorporating our custom experiment runner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### First, let's reinitialize the state object to get a clean state ####\n",
    "iv = Variable(name=\"x\", value_range=(0, 2 * np.pi), allowed_values=np.linspace(0, 2 * np.pi, 30))\n",
    "dv = Variable(name=\"y\", type=ValueType.REAL)\n",
    "variables = VariableCollection(independent_variables=[iv],dependent_variables=[dv])\n",
    "\n",
    "conditions = random_pool(variables, num_samples=10, random_state=0)\n",
    "\n",
    "s = StandardState(variables = variables, conditions = conditions, experiment_data = pd.DataFrame(columns=[\"x\",\"y\"]))\n",
    "\n",
    "#Report previous state\n",
    "print('\\033[1mPrevious State:\\033[0m')\n",
    "print(s)\n",
    "\n",
    "#Cycle\n",
    "for cycle in range(5):\n",
    "    s = experimentalist(s, num_samples = 10, random_state=42+cycle)\n",
    "    s = custom_experiment_runner(s, added_noise=0.5, random_state=42+cycle)\n",
    "    s = theorist(s)\n",
    "    \n",
    "    plot_from_state(s, 'x + x**2')\n",
    "\n",
    "#Report updated state\n",
    "print('\\n\\033[1mUpdated State:\\033[0m')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Theorists\n",
    "\n",
    "Theorists must be implemented as classes that inherit from  `sklearn.base.BaseEstimator`. The class must implement the following methods:\n",
    "\n",
    "- `fit(self, conditions, observations)`\n",
    "- `predict(self, conditions)`\n",
    "\n",
    "**Requirements for working with the state:**\n",
    "- The fit module function has a `conditions` argument that accepts a `pandas.DataFrame`\n",
    "- The fit module function has an `observations` argument that accepts a `pandas.DataFrame`\n",
    "- the fit function returns `self` (i.e., the model itself)\n",
    "\n",
    "The custom `PolynomialRegressor` below fits a polynomial of a specified degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class PolynomialRegressor(BaseEstimator):\n",
    "\n",
    "    def __init__(self, degree: int = 3):\n",
    "        self.degree = degree\n",
    "\n",
    "    def fit(self, conditions: pd.DataFrame, observations: pd.DataFrame):\n",
    "        c = np.array(conditions)\n",
    "        o = np.array(observations)\n",
    "\n",
    "        # polyfit expects a 1D array\n",
    "        if c.ndim > 1:\n",
    "            c = c.flatten()\n",
    "\n",
    "        if o.ndim > 1:\n",
    "            o = o.flatten()\n",
    "\n",
    "        # fit polynomial\n",
    "        self.coeff = np.polyfit(c, o, self.degree)\n",
    "        self.polynomial = np.poly1d(self.coeff)\n",
    "        return self\n",
    "\n",
    "    def predict(self, conditions: pd.DataFrame):\n",
    "        c = np.array(conditions)\n",
    "        return self.polynomial(c)\n",
    "    \n",
    "custom_theorist = estimator_on_state(PolynomialRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will re-run our initial workflow while incorporating our custom theorist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### First, let's reinitialize the state object to get a clean state ####\n",
    "iv = Variable(name=\"x\", value_range=(0, 2 * np.pi), allowed_values=np.linspace(0, 2 * np.pi, 30))\n",
    "dv = Variable(name=\"y\", type=ValueType.REAL)\n",
    "variables = VariableCollection(independent_variables=[iv],dependent_variables=[dv])\n",
    "\n",
    "conditions = random_pool(variables, num_samples=10, random_state=0)\n",
    "\n",
    "s = StandardState(variables = variables, conditions = conditions, experiment_data = pd.DataFrame(columns=[\"x\",\"y\"]))\n",
    "\n",
    "#Report previous state\n",
    "print('\\033[1mPrevious State:\\033[0m')\n",
    "print(s)\n",
    "\n",
    "#Cycle\n",
    "for cycle in range(5):\n",
    "    s = experimentalist(s, num_samples=10, random_state=42+cycle)\n",
    "    s = experiment_runner(s, added_noise=0.5, random_state=42+cycle)\n",
    "    s = custom_theorist(s)\n",
    "    \n",
    "    print(s.models[-1])\n",
    "    plot_from_state(s, 'sin(x)')\n",
    "\n",
    "#Report updated state\n",
    "print('\\n\\033[1mUpdated State:\\033[0m')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Altogether Now\n",
    "\n",
    "We have now created custom experimentalists, experiment runners, and theorists. Let's add them all to the same workflow to see our first fully customized `autora` workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### First, let's reinitialize the state object to get a clean state ####\n",
    "iv = Variable(name=\"x\", value_range=(0, 2 * np.pi), allowed_values=np.linspace(0, 2 * np.pi, 30))\n",
    "dv = Variable(name=\"y\", type=ValueType.REAL)\n",
    "variables = VariableCollection(independent_variables=[iv],dependent_variables=[dv])\n",
    "\n",
    "conditions = random_pool(variables, num_samples=10, random_state=0)\n",
    "\n",
    "s = StandardState(variables = variables, conditions = conditions, experiment_data = pd.DataFrame(columns=[\"x\",\"y\"]))\n",
    "\n",
    "#Report previous state\n",
    "print('\\033[1mPrevious State:\\033[0m')\n",
    "print(s)\n",
    "\n",
    "#Cycle\n",
    "for cycle in range(5):\n",
    "    s = custom_experimentalist(s, num_samples=10, random_state=42+cycle)\n",
    "    s = custom_experiment_runner(s, added_noise=0.5, random_state=42+cycle)\n",
    "    s = custom_theorist(s)\n",
    "    \n",
    "    plot_from_state(s, 'x + x**2')\n",
    "\n",
    "#Report updated state\n",
    "print('\\n\\033[1mUpdated State:\\033[0m')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the controller with the new theorist for 3 research cycles, defined by the number of models generated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Help\n",
    "We hope that this tutorial helped demonstrate the fundamental components of ``autora``, and how they can be combined to facilitate automated (closed-loop) empirical research through synthetic experiments. We encourage you to explore other [tutorials](https://autoresearch.github.io/autora/tutorials/) and check out the [documentation](https://autoresearch.github.io/autora/).\n",
    "\n",
    "If you encounter any issues, bugs, or questions, please reach out to us through the [AutoRA Forum](https://github.com/orgs/AutoResearch/discussions). Feel free to report any bugs by [creating an issue in the AutoRA repository](https://github.com/AutoResearch/autora/issues).\n",
    "\n",
    "You may also post questions directly into the [User Q&A Section](https://github.com/orgs/AutoResearch/discussions/categories/using-autora).\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "autora_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
