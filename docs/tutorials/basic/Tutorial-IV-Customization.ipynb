{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[AutoRA](https://pypi.org/project/autora/)** (**Au**tomated **R**esearch **A**ssistant) is an open-source framework designed to automate various stages of empirical research, including model discovery, experimental design, and data collection.\n",
    "\n",
    "This notebook is the fourth of four notebooks within the basic tutorials of ``autora``. We suggest that you go through these notebooks in order as each builds upon the last. However, each notebook is self-contained and so there is no need to *run* the content of the last notebook for your current notebook. We will here provide a link to each notebook, but we will also provide a link at the end of each notebook to navigate you to the next notebook.\n",
    "\n",
    "[AutoRA Basic Tutorial I: Components](https://autoresearch.github.io/autora/tutorials/basic/Tutorial-I-Components/) <br>\n",
    "[AutoRA Basic Tutorial II: Loop Constructs](https://autoresearch.github.io/autora/tutorials/basic/Tutorial-II-Loop-Constructs/) <br>\n",
    "[AutoRA Basic Tutorial III: Functional Workflow](https://autoresearch.github.io/autora/tutorials/basic/Tutorial-III-Functional-Workflow/) <br>\n",
    "[AutoRA Basic Tutorial IV: Customization](https://autoresearch.github.io/autora/tutorials/basic/Tutorial-IV-Customization/) <br>\n",
    "\n",
    "These notebooks provide a comprehensive introduction to the capabilities of ``autora``. **It demonstrates the fundamental components of ``autora``, and how they can be combined to facilitate automated (closed-loop) empirical research through synthetic experiments.**\n",
    "\n",
    "**How to use this notebook** *You can progress through the notebook section by section or directly navigate to specific sections. If you choose the latter, it is recommended to execute all cells in the notebook initially, allowing you to easily rerun the cells in each section later without issues.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Installation ####\n",
    "!pip install -q \"autora[theorist-bms]\"\n",
    "\n",
    "#### Import modules ####\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from autora.variable import DV, IV, ValueType, VariableCollection\n",
    "from autora.state.bundled import StandardState\n",
    "from autora.state.delta import on_state\n",
    "from autora.state.wrapper import state_fn_from_estimator\n",
    "from autora.experimentalist.random_ import random_pool\n",
    "from autora.theorist.bms import BMSRegressor\n",
    "\n",
    "#### Set seeds ####\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customizing Automated Empirical Research Components\n",
    "\n",
    "``autora`` is a flexible framework in which users can integrate their own theorists, experimentalists, and experiment_runners in aa automated empirical research workflow. This section illustrates the integration of custom theorists and experimentalists. For more information on how to contribute your own modules to the ``autora`` ecosystem, please refer to the [Contributor Documentation](https://autoresearch.github.io/autora/contribute/modules/).\n",
    "\n",
    "To illustrate the use of custom theorists and experimentalists, we consider a simple workflow:\n",
    "1. Generate 10 seed experimental conditions using `random_pool`\n",
    "2. Iterate through the following steps\n",
    "   - Collect observations using the ``experiment_runner``\n",
    "   - Identify a model relating conditions to observations using a ``theorist``\n",
    "   - Identify 3 new experimental conditions using an ``experimentalist``\n",
    "\n",
    "Once this workflow is setup, we will replace each component with a custom function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define metadata ####\n",
    "iv = IV(name=\"x\", value_range=(0, 2 * np.pi), allowed_values=np.linspace(0, 2 * np.pi, 10))\n",
    "dv = DV(name=\"y\", type=ValueType.REAL)\n",
    "variables = VariableCollection(independent_variables=[iv],dependent_variables=[dv])\n",
    "\n",
    "#### Define condition pool ####\n",
    "conditions = random_pool(variables, num_samples=10)\n",
    "\n",
    "#### Define state ####\n",
    "s = StandardState(\n",
    "    variables = variables,\n",
    "    conditions = conditions,\n",
    "    experiment_data = pd.DataFrame(columns=[\"x\",\"y\"])\n",
    ")\n",
    "\n",
    "#### Define experiment runner and wrap with state functionality ####\n",
    "def run_experiment(conditions: pd.DataFrame):\n",
    "    x = conditions[\"x\"]\n",
    "    y = np.sin(x) + np.random.normal(0, 0.5, size=x.shape)\n",
    "    observations = conditions.assign(y = y)\n",
    "    return observations\n",
    "\n",
    "experiment_runner = on_state(run_experiment, output=[\"experiment_data\"])\n",
    "\n",
    "#### Define theorist and wrap with state functionality ####\n",
    "theorist = state_fn_from_estimator(BMSRegressor(epochs=100))\n",
    "\n",
    "#### Define experimentalist and wrap with state functionality ####\n",
    "experimentalist = on_state(random_pool, output=[\"conditions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should quickly test to make sure everything works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\033[1mPrevious State:\\033[0m')\n",
    "print(s)\n",
    "\n",
    "for cycle in range(2):\n",
    "    s = theorist(experiment_runner(experimentalist(s)))\n",
    "\n",
    "print('\\n\\033[1mUpdated State:\\033[0m')\n",
    "print(s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Theorists\n",
    "\n",
    "What if we wanted to replace the ``theorist`` with a custom theorist?\n",
    "\n",
    "We can implement our theorist as a class that inherits from  `sklearn.base.BaseEstimator`. The class must implement the following methods:\n",
    "\n",
    "- `fit(self, conditions, observations)`\n",
    "- `predict(self, conditions)`\n",
    "\n",
    "The following code block implements such a theorist that fits a polynomial of a specified degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class PolynomialRegressor(BaseEstimator):\n",
    "    \"\"\"\n",
    "    This theorist fits a polynomial function to the data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, degree: int = 3):\n",
    "        self.degree = degree\n",
    "\n",
    "    def fit(self, conditions, observations):\n",
    "\n",
    "        # polyfit expects a 1D array\n",
    "        if conditions.ndim > 1:\n",
    "            conditions = conditions.flatten()\n",
    "\n",
    "        if observations.ndim > 1:\n",
    "            observations = observations.flatten()\n",
    "\n",
    "        # fit polynomial\n",
    "        self.coeff = np.polyfit(conditions, observations, self.degree)\n",
    "        self.polynomial = np.poly1d(self.coeff)\n",
    "        pass\n",
    "\n",
    "    def predict(self, conditions):\n",
    "        return self.polynomial(conditions)\n",
    "    \n",
    "custom_theorist = state_fn_from_estimator(PolynomialRegressor())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the controller with the new theorist for 3 research cycles, defined by the number of models generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### First, let's reinitialize the state object to get a clean state ####\n",
    "s = StandardState(variables = variables, conditions = conditions, experiment_data = pd.DataFrame(columns=[\"x\",\"y\"]))\n",
    "\n",
    "print('\\033[1mPrevious State:\\033[0m')\n",
    "print(s)\n",
    "\n",
    "for cycle in range(5):\n",
    "    s = custom_theorist(experiment_runner(experimentalist(s)))\n",
    "\n",
    "print('\\n\\033[1mUpdated State:\\033[0m')\n",
    "print(s)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Experimentalists\n",
    "\n",
    "We can also implement custom experimentalists. Experimentalists are generally implemented as functions that can be integrated into an\n",
    "[Experimentalist Pipeline](https://autoresearch.github.io/autora/core/docs/pipeline/Experimentalist%20Pipeline%20Examples/). For instance, an experimentalist sampler function expects a pool of experimental conditions–typically passed as a 2D numpy array named ``condition_pool``–and returns a modified set of experimental conditions.\n",
    "\n",
    "The following code block implements a basic experimentalist that considers two models, and identifies experimental conditions for which the two models differ most in their predictions. This is a special case of the [Model Disagreement Sampler](https://autoresearch.github.io/autora/user-guide/experimentalists/samplers/model-disagreement/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_experimentalist(variables: VariableCollection, conditions: pd.DataFrame, num_samples = 1):\n",
    "\n",
    "    \"\"\"\n",
    "    An experimentalist that selects the least represented datapoints\n",
    "    \"\"\"\n",
    "\n",
    "    #Retrieve the possible values\n",
    "    allowed_values = variables.independent_variables[0].allowed_values\n",
    "    \n",
    "    #Determine the representation of each value\n",
    "    conditions_count = np.array([conditions[\"x\"].isin([value]).sum(axis=0) for value in allowed_values])\n",
    "    \n",
    "    #Sort to determine the least represented values\n",
    "    conditions_sort = conditions_count.argsort()\n",
    "    values_count = allowed_values[conditions_sort]\n",
    "    \n",
    "    return pd.DataFrame({\"x\": values_count[:num_samples]})\n",
    "\n",
    "custom_experimentalist = on_state(uniform_experimentalist, output=[\"conditions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPrevious State:\u001b[0m\n",
      "StandardState(variables=VariableCollection(independent_variables=[IV(name='x', value_range=(0, 6.283185307179586), allowed_values=array([0.        , 0.6981317 , 1.3962634 , 2.0943951 , 2.7925268 ,\n",
      "       3.4906585 , 4.1887902 , 4.88692191, 5.58505361, 6.28318531]), units='', type=<ValueType.REAL: 'real'>, variable_label='Independent Variable', rescale=1, is_covariate=False)], dependent_variables=[DV(name='y', value_range=None, allowed_values=None, units='', type=<ValueType.REAL: 'real'>, variable_label='Dependent Variable', rescale=1, is_covariate=False)], covariates=[]), conditions=          x\n",
      "0  4.886922\n",
      "1  4.886922\n",
      "2  0.698132\n",
      "3  2.792527\n",
      "4  0.698132\n",
      "5  4.886922\n",
      "6  0.000000\n",
      "7  4.886922\n",
      "8  0.698132\n",
      "9  1.396263, experiment_data=Empty DataFrame\n",
      "Columns: [x, y]\n",
      "Index: [], models=[])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (5) does not match length of index (10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(s)\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m cycle \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n\u001b[1;32m----> 8\u001b[0m     s \u001b[39m=\u001b[39m theorist(experiment_runner(custom_experimentalist(s, num_samples \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m)))\n\u001b[0;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\033\u001b[39;00m\u001b[39m[1mUpdated State:\u001b[39m\u001b[39m\\033\u001b[39;00m\u001b[39m[0m\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(s)\n",
      "File \u001b[1;32mc:\\Users\\cwill\\GitHub\\virtualEnvs\\autoraEnv\\lib\\site-packages\\autora\\state\\delta.py:1033\u001b[0m, in \u001b[0;36mdelta_to_state.<locals>._f\u001b[1;34m(state_, **kwargs)\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m   1032\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_f\u001b[39m(state_: S, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m S:\n\u001b[1;32m-> 1033\u001b[0m     delta \u001b[39m=\u001b[39m f(state_, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1034\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(delta, Mapping), (\n\u001b[0;32m   1035\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOutput of \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must be a `Delta`, `UserDict`, \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mor `dict`.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m f\n\u001b[0;32m   1036\u001b[0m     )\n\u001b[0;32m   1037\u001b[0m     new_state \u001b[39m=\u001b[39m state_ \u001b[39m+\u001b[39m delta\n",
      "File \u001b[1;32mc:\\Users\\cwill\\GitHub\\virtualEnvs\\autoraEnv\\lib\\site-packages\\autora\\state\\delta.py:768\u001b[0m, in \u001b[0;36minputs_from_state.<locals>._f\u001b[1;34m(state_, **kwargs)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mconditions\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m arguments \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(arguments[\u001b[39m\"\u001b[39m\u001b[39mconditions\u001b[39m\u001b[39m\"\u001b[39m], pd\u001b[39m.\u001b[39mDataFrame) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    762\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mvariables\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m [i\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m fields(state_)]):\n\u001b[0;32m    763\u001b[0m     arguments[\u001b[39m\"\u001b[39m\u001b[39mconditions\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m (\n\u001b[0;32m    764\u001b[0m         align_dataframe_to_ivs(arguments[\u001b[39m\"\u001b[39m\u001b[39mconditions\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    765\u001b[0m                                \u001b[39mgetattr\u001b[39m(state_, \u001b[39m\"\u001b[39m\u001b[39mvariables\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mindependent_variables)\n\u001b[0;32m    766\u001b[0m     )\n\u001b[1;32m--> 768\u001b[0m result \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39marguments)\n\u001b[0;32m    769\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\cwill\\GitHub\\virtualEnvs\\autoraEnv\\lib\\site-packages\\autora\\state\\delta.py:851\u001b[0m, in \u001b[0;36moutputs_to_delta.<locals>.decorator.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    850\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 851\u001b[0m     result \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    852\u001b[0m     delta \u001b[39m=\u001b[39m Delta(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{output[\u001b[39m0\u001b[39m]: result})\n\u001b[0;32m    853\u001b[0m     \u001b[39mreturn\u001b[39;00m delta\n",
      "Cell \u001b[1;32mIn[88], line 17\u001b[0m, in \u001b[0;36muniform_experimentalist\u001b[1;34m(variables, conditions, num_samples)\u001b[0m\n\u001b[0;32m     14\u001b[0m conditions_sort \u001b[39m=\u001b[39m conditions_count\u001b[39m.\u001b[39margsort()\n\u001b[0;32m     15\u001b[0m values_count \u001b[39m=\u001b[39m allowed_values[conditions_sort]\n\u001b[1;32m---> 17\u001b[0m \u001b[39mreturn\u001b[39;00m conditions\u001b[39m.\u001b[39;49massign(x\u001b[39m=\u001b[39;49mvalues_count[:num_samples])\n",
      "File \u001b[1;32mc:\\Users\\cwill\\GitHub\\virtualEnvs\\autoraEnv\\lib\\site-packages\\pandas\\core\\frame.py:4844\u001b[0m, in \u001b[0;36mDataFrame.assign\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   4841\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m   4843\u001b[0m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems():\n\u001b[1;32m-> 4844\u001b[0m     data[k] \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(v, data)\n\u001b[0;32m   4845\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\cwill\\GitHub\\virtualEnvs\\autoraEnv\\lib\\site-packages\\pandas\\core\\frame.py:3950\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3947\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3948\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3949\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[1;32m-> 3950\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[1;32mc:\\Users\\cwill\\GitHub\\virtualEnvs\\autoraEnv\\lib\\site-packages\\pandas\\core\\frame.py:4143\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4134\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4135\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4136\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4141\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4142\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4143\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[0;32m   4145\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   4146\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m   4147\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   4148\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   4149\u001b[0m     ):\n\u001b[0;32m   4150\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4151\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32mc:\\Users\\cwill\\GitHub\\virtualEnvs\\autoraEnv\\lib\\site-packages\\pandas\\core\\frame.py:4870\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4867\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[0;32m   4869\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4870\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[0;32m   4871\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\cwill\\GitHub\\virtualEnvs\\autoraEnv\\lib\\site-packages\\pandas\\core\\common.py:576\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[1;32m--> 576\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    577\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    579\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (5) does not match length of index (10)"
     ]
    }
   ],
   "source": [
    "#### First, let's reinitialize the state object to get a clean state ####\n",
    "s = StandardState(variables = variables, conditions = conditions, experiment_data = pd.DataFrame(columns=[\"x\",\"y\"]))\n",
    "\n",
    "print('\\033[1mPrevious State:\\033[0m')\n",
    "print(s)\n",
    "\n",
    "for cycle in range(5):\n",
    "    s = theorist(experiment_runner(custom_experimentalist(s, num_samples = 5)))\n",
    "\n",
    "print('\\n\\033[1mUpdated State:\\033[0m')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Experiment Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sine_experiment_runner(conditions: pd.DataFrame, added_noise: float = 0.5):\n",
    "    x = conditions[\"x\"]\n",
    "    y = np.sin(x) + np.random.normal(0, added_noise, size=x.shape)\n",
    "    observations = conditions.assign(y = y)\n",
    "    return observations\n",
    "\n",
    "custom_experiment_runner = on_state(sine_experiment_runner, output=[\"experiment_data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### First, let's reinitialize the state object to get a clean state ####\n",
    "s = StandardState(variables = variables, conditions = conditions, experiment_data = pd.DataFrame(columns=[\"x\",\"y\"]))\n",
    "\n",
    "print('\\033[1mPrevious State:\\033[0m')\n",
    "print(s)\n",
    "\n",
    "for cycle in range(5):\n",
    "    s = theorist(custom_experiment_runner(experimentalist(s, num_samples = 5)))\n",
    "\n",
    "print('\\n\\033[1mUpdated State:\\033[0m')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Altogether Now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### First, let's reinitialize the state object to get a clean state ####\n",
    "s = StandardState(variables = variables, conditions = conditions, experiment_data = pd.DataFrame(columns=[\"x\",\"y\"]))\n",
    "\n",
    "print('\\033[1mPrevious State:\\033[0m')\n",
    "print(s)\n",
    "\n",
    "for cycle in range(5):\n",
    "    s = custom_theorist(custom_experiment_runner(custom_experimentalist(s, num_samples = 5)))\n",
    "\n",
    "print('\\n\\033[1mUpdated State:\\033[0m')\n",
    "print(s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Help\n",
    "We hope that this tutorial helped demonstrate the fundamental components of ``autora``, and how they can be combined to facilitate automated (closed-loop) empirical research through synthetic experiments. We encourage you to explore other [tutorials](https://autoresearch.github.io/autora/tutorials/) and check out the [documentation](https://autoresearch.github.io/).\n",
    "\n",
    "If you encounter any issues, bugs, or questions, please reach out to us through the [AutoRA Forum](https://github.com/orgs/AutoResearch/discussions). Feel free to report any bugs by [creating an issue in the AutoRA repository](https://github.com/AutoResearch/autora/issues).\n",
    "\n",
    "You may also post questions directly into the [User Q&A Section](https://github.com/orgs/AutoResearch/discussions/categories/using-autora).\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "autoraKernel",
   "language": "python",
   "name": "autorakernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
