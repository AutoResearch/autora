{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "## Basic Tutorial II: Loop Constructs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[AutoRA](https://pypi.org/project/autora/)** (**Au**tomated **R**esearch **A**ssistant) is an open-source framework designed to automate various stages of empirical research, including model discovery, experimental design, and data collection.\n",
    "\n",
    "This notebook is the second of four notebooks within the basic tutorials of ``autora``. We suggest that you go through these notebooks in order as each builds upon the last. However, each notebook is self-contained and so there is no need to *run* the content of the last notebook for your current notebook. We will here provide a link to each notebook, but we will also provide a link at the end of each notebook to navigate you to the next notebook.\n",
    "\n",
    "[AutoRA Basic Tutorial I: Components](https://autoresearch.github.io/autora/tutorials/basic/Tutorial-I-Components/) <br>\n",
    "[AutoRA Basic Tutorial II: Loop Constructs](https://autoresearch.github.io/autora/tutorials/basic/Tutorial-II-Loop-Constructs/) <br>\n",
    "[AutoRA Basic Tutorial III: Functional Workflow](https://autoresearch.github.io/autora/tutorials/basic/Tutorial-III-Functional-Workflow/) <br>\n",
    "[AutoRA Basic Tutorial IV: Customization](https://autoresearch.github.io/autora/tutorials/basic/Tutorial-IV-Customization/) <br>\n",
    "\n",
    "These notebooks provide a comprehensive introduction to the capabilities of ``autora``. **It demonstrates the fundamental components of ``autora``, and how they can be combined to facilitate automated (closed-loop) empirical research through synthetic experiments.**\n",
    "\n",
    "**How to use this notebook** *You can progress through the notebook section by section or directly navigate to specific sections. If you choose the latter, it is recommended to execute all cells in the notebook initially, allowing you to easily rerun the cells in each section later without issues.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Setup\n",
    "This tutorial is self-contained so that you do not need to run the previous notebook to begin. However, the four notebooks are continuous so that what we define in a previous notebook should still exist within this notebook. As such, we will here re-run relevant code from past tutorials. We will not again walk you through these, but if you need a reminder what they are then go see the descriptions in previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "WARNING: autora 3.1.1 does not provide the extra 'experimentalist-model-disagreement'\n",
      "\n",
      "[notice] A new release of pip is available: 23.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 23.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#### Installation ####\n",
    "!pip install -q \"autora[experimentalist-falsification]\"\n",
    "!pip install -q \"autora[experimentalist-model-disagreement]\"\n",
    "!pip install -q \"autora[theorist-bms]\"\n",
    "\n",
    "#### Import modules ####\n",
    "import numpy as np\n",
    "import torch\n",
    "from autora.variable import Variable, ValueType, VariableCollection\n",
    "from autora.experimentalist.random import random_pool\n",
    "from autora.experimentalist.falsification import falsification_sample\n",
    "from autora.experimentalist.model_disagreement import model_disagreement_sample\n",
    "from autora.theorist.bms import BMSRegressor\n",
    "from sklearn import linear_model\n",
    "\n",
    "#### Set seeds ####\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "#### Define ground truth and experiment runner ####\n",
    "ground_truth = lambda x: np.sin(x)\n",
    "run_experiment = lambda x: ground_truth(x) + np.random.normal(0, 0.1, size=x.shape)\n",
    "\n",
    "#### Define condition pool ####\n",
    "condition_pool = np.linspace(0, 2 * np.pi, 100)\n",
    "\n",
    "#### Define variables ####\n",
    "iv = Variable(name=\"x\", value_range=(0, 2 * np.pi), allowed_values=condition_pool)\n",
    "dv = Variable(name=\"y\", type=ValueType.REAL)\n",
    "variables = VariableCollection(independent_variables=[iv],dependent_variables=[dv])\n",
    "\n",
    "#### Define theorists ####\n",
    "theorist_lr = linear_model.LinearRegression()\n",
    "theorist_bms = BMSRegressor(epochs=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop Constructs\n",
    "After defining all the components required for the empirical research process, we can create an automated workflow using basic loop constructs in Python.\n",
    "\n",
    "The following code block demonstrates how to build such a workflow using the components introduced in the preceding notebook, such as\n",
    "\n",
    "- ``variables`` (object specifying variables of the experiment) <br>\n",
    "- ``run_experiment`` (function for collecting data) <br>\n",
    "- ``theorist_bms`` (scikit learn estimator for discovering equations using the Bayesian Machine Scientist) <br>\n",
    "- ``random_pool`` (function for generating a random pool of experimental conditions) <br>\n",
    "- ``falsification_sample`` (function for identifying novel experiment conditions using the falsification sampler) <br>\n",
    "\n",
    "We begin with implementing the following workflow:\n",
    "1. Generate 3 seed experimental conditions using ``random_pool``\n",
    "2. Generate 3 seed observations using ``run_experiment``\n",
    "3. Loop through the following steps 5 times\n",
    "   - Identify a model relating conditions to observations using ``theorist_bms``\n",
    "   - Identify 3 new experimental conditions using ``falsification_sample``\n",
    "   - Collect 3 new observations using ``run_experiment``\n",
    "   - Add new conditions and observations to the dataset\n",
    "\n",
    "We will here begin using the naming convention ``cycle`` to refer to an entire AutoRA loop where the loop encounters all AutoRA components - experiment runner, theorist, experimentalist. Within the scientific method, a cycle would then be running a single iteration of the experiment. This requires the collection of data, the modelling of that data, and the conceptualization of the next iteration of this experiment. For example, if our research concerns how much information a person acquires from a photo (dependent variable) dependent on how bright the photo is (independent variable), we may first collect data with conditions of (let's say) 10%, 50%, and 90% brightness, then model our collected data to determine the relationship between brightness and photo perception, and finally determine which other brightness conditions may help us understand the true relationship. Probing other conditions - such as a brightness of 25% and of 75% would then be the next iteration of the experiment and thus, for us, the next cycle. The following code block will iterate through five of these cycles."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Falsification Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autora.theorist.bms.regressor:BMS fitting started\n",
      "100%|██████████| 100/100 [00:04<00:00, 23.65it/s]\n",
      "INFO:autora.theorist.bms.regressor:BMS fitting finished\n",
      "INFO:autora.theorist.bms.regressor:BMS fitting started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.28318531]\n",
      " [6.21971879]\n",
      " [6.15625227]]\n",
      "Loss in cycle 0: 1.0728386415534816\n",
      "Discovered Model: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 23.15it/s]\n",
      "INFO:autora.theorist.bms.regressor:BMS fitting finished\n",
      "INFO:autora.theorist.bms.regressor:BMS fitting started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.28318531]\n",
      " [6.21971879]\n",
      " [1.3962634 ]]\n",
      "Loss in cycle 1: 0.99\n",
      "Discovered Model: sin(X0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 20.20it/s]\n",
      "INFO:autora.theorist.bms.regressor:BMS fitting finished\n",
      "INFO:autora.theorist.bms.regressor:BMS fitting started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.25225672]\n",
      " [4.31572324]\n",
      " [4.1887902 ]]\n",
      "Loss in cycle 2: inf\n",
      "Discovered Model: (1.29 / X0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 24.55it/s]\n",
      "INFO:autora.theorist.bms.regressor:BMS fitting finished\n",
      "INFO:autora.theorist.bms.regressor:BMS fitting started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        ]\n",
      " [0.06346652]\n",
      " [0.12693304]]\n",
      "Loss in cycle 3: 0.4973522295525592\n",
      "Discovered Model: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 24.49it/s]\n",
      "INFO:autora.theorist.bms.regressor:BMS fitting finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06346652]\n",
      " [0.12693304]\n",
      " [0.19039955]]\n",
      "Loss in cycle 4: 0.99\n",
      "Discovered Model: sin(X0)\n"
     ]
    }
   ],
   "source": [
    "num_cycles = 5 # number of empirical research cycles\n",
    "measurements_per_cycle = 3 # number of data points to collect for each cycle\n",
    "\n",
    "# generate an initial set of experimental conditions\n",
    "conditions = random_pool(variables=variables,\n",
    "                         num_samples=measurements_per_cycle)\n",
    "\n",
    "# convert iterator into 2-dimensional numpy array\n",
    "conditions = np.array(list(conditions.values)).reshape(-1, 1)\n",
    "\n",
    "# collect initial set of observations\n",
    "observations = run_experiment(conditions)\n",
    "\n",
    "for cycle in range(num_cycles):\n",
    "\n",
    "  # use BMS theorist to fit the model to the data\n",
    "  theorist_bms.fit(conditions, observations)\n",
    "\n",
    "  # obtain new conditions\n",
    "  new_conditions = falsification_sample(\n",
    "          conditions=condition_pool,\n",
    "          model=theorist_bms,\n",
    "          reference_conditions=conditions,\n",
    "          reference_observations=observations,\n",
    "          metadata=variables,\n",
    "          num_samples=measurements_per_cycle,\n",
    "      )\n",
    "\n",
    "  # obtain new observations\n",
    "  print(new_conditions)\n",
    "  new_observations = run_experiment(new_conditions)\n",
    "\n",
    "  # combine old and new conditions and observations\n",
    "  conditions = np.concatenate((conditions, new_conditions))\n",
    "  observations = np.concatenate((observations, new_observations))\n",
    "\n",
    "  # evaluate model of the theorist based on its ability to predict each observation from the ground truth, evaluated across the entire space of experimental conditions\n",
    "  loss = np.mean(np.square(theorist_bms.predict(condition_pool.reshape(-1,1)) - ground_truth(condition_pool)))\n",
    "  print(\"Loss in cycle {}: {}\".format(cycle, loss))\n",
    "  print(\"Discovered Model: \" +  theorist_bms.repr())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Model Disagreement Sampler\n",
    "We can easily replace components in the workflow above.\n",
    "\n",
    "In the following code block, we add a linear regression theorist, to fit a linear model to the data. In addition, we replace ``falsification_sample`` with  ``model_disagreement_sample`` to sample experimental conditions that differentiate most between the linear model and the model discovered by the BMS theorist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autora.theorist.bms.regressor:BMS fitting started\n",
      "100%|██████████| 100/100 [00:04<00:00, 23.55it/s]\n",
      "INFO:autora.theorist.bms.regressor:BMS fitting finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0\n",
      "99  6.283185\n",
      "98  6.219719\n",
      "97  6.156252\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10828\\1882676081.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m   \u001b[0mnew_observations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_conditions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m   \u001b[1;31m# combine old and new conditions and observations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m   \u001b[0mconditions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconditions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_conditions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m   \u001b[0mobservations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_observations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m   \u001b[1;31m# evaluate model of the theorist based on its ability to predict each observation from the ground truth, evaluated across the entire space of experimental conditions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m   \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheorist_bms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcondition_pool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcondition_pool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cwill\\GitHub\\virtualEnvs\\autoraEnv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5985\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5986\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5987\u001b[0m         ):\n\u001b[0;32m   5988\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5989\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "num_cycles = 5 # number of empirical research cycles\n",
    "measurements_per_cycle = 3 # number of data points to collect for each cycle\n",
    "\n",
    "# generate an initial set of experimental conditions\n",
    "conditions = random_pool(variables=variables,\n",
    "                         num_samples=measurements_per_cycle)\n",
    "\n",
    "# convert iterator into 2-dimensional numpy array\n",
    "conditions = np.array(list(conditions.values)).reshape(-1, 1)\n",
    "\n",
    "# collect initial set of observations\n",
    "observations = run_experiment(conditions)\n",
    "\n",
    "for cycle in range(num_cycles):\n",
    "\n",
    "  # use BMS theorist to fit the model to the data\n",
    "  theorist_bms.fit(conditions, observations)\n",
    "  theorist_lr.fit(conditions, observations)\n",
    "\n",
    "  # obtain new conditions\n",
    "  new_conditions = model_disagreement_sample(\n",
    "          condition_pool,\n",
    "          models = [theorist_bms, theorist_lr],\n",
    "          num_samples = measurements_per_cycle\n",
    "      )\n",
    "\n",
    "  # obtain new observations\n",
    "  print(new_conditions)\n",
    "  new_observations = run_experiment(new_conditions)\n",
    "\n",
    "  # combine old and new conditions and observations\n",
    "  conditions = np.concatenate((conditions, new_conditions))\n",
    "  observations = np.concatenate((observations, new_observations))\n",
    "\n",
    "  # evaluate model of the theorist based on its ability to predict each observation from the ground truth, evaluated across the entire space of experimental conditions\n",
    "  loss = np.mean(np.square(theorist_bms.predict(condition_pool.reshape(-1,1)) - ground_truth(condition_pool)))\n",
    "  print(\"Loss in cycle {}: {}\".format(cycle, loss))\n",
    "  print(\"Discovered BMS Model: \" +  theorist_bms.repr())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Notebook\n",
    "While the basic loop construct is flexible, there are more convenient ways to specify a research cycle in ``autora``. The next notebook illustrates the use of these constructs.\n",
    "\n",
    "Follow this link for the next notebook tutorial:\n",
    "[AutoRA Basic Tutorial III: Functional Workflow](https://autoresearch.github.io/autora/tutorials/basic/Tutorial-III-Workflow-Logic/) <br>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "autoraEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
