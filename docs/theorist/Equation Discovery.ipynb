{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Equation Discovery With The Bayesian Machine Scientist \n",
    "\n",
    "In this tutorial we will demonstrate how to autonomously recover equations from data using the Bayesian Machine Scientist. We will follow the sci-kit learn workflow.\n",
    "\n",
    "Note: this tutorial requires Python 3.10 to run successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Model Recovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Install relevant subpackages from AutoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix default prior and release new package version\n",
    "!pip install -q \"autora[theorist-bms]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Import relevant modules from AutoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autora.theorist.bms import BMSRegressor\n",
    "from autora.experiment_runner.synthetic.psychophysics.weber_fechner_law import weber_fechner_law\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Import your data\n",
    "*(Here we create noisy synthetic data as a demonstration)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant = 3.0\n",
    "\n",
    "# synthetic experiment from autora inventory\n",
    "synthetic_runner = weber_fechner_law(constant=constant)\n",
    "\n",
    "# experiment meta data:\n",
    "synthetic_runner.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent variables\n",
    "ivs = [iv.name for iv in synthetic_runner.variables.independent_variables]\n",
    "\n",
    "# dependent variable\n",
    "dvs = [dv.name for dv in synthetic_runner.variables.dependent_variables]\n",
    "\n",
    "ivs, dvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimental data\n",
    "conditions = synthetic_runner.domain()\n",
    "experiment_data = synthetic_runner.run(conditions, added_noise=0.01)\n",
    "\n",
    "experiment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observations\n",
    "observations = experiment_data[dvs]\n",
    "\n",
    "# split into train and test datasets\n",
    "conditions_train, conditions_test, observations_train, observations_test = train_test_split(conditions, observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will repeat these steps for each model\n",
    "4. Initialize Model\n",
    "5. Fit Model to the Data\n",
    "6. Plot the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Functions you can use to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def present_results(model, x_test, y_test, arg='default', model_name=None, variable_names=None, select_indices=None, figsize=None, *args):\n",
    "  compare_results(models=[model], x_test=x_test, y_test=y_test, arg=arg, model_names=[model_name], variable_names=variable_names, select_indices=select_indices, figsize=figsize, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(models, x_test, y_test, arg='default', model_names=None, variable_names=None, observation_name=None, select_indices=None, figsize=None, *args):\n",
    "  if model_names is None or model_names == [None]:\n",
    "    names = ['Model '+str(i+1) for i in range(len(models))]\n",
    "  else:\n",
    "    names = model_names\n",
    "  if len(x_test.shape) == 1:\n",
    "    x_test = x_test.reshape(1, -1)\n",
    "  num_var = x_test.shape[1]\n",
    "  if variable_names is None:\n",
    "    var_names = ['Variable '+str(i+1) for i in range(num_var)]\n",
    "  else:\n",
    "    var_names = variable_names\n",
    "  if observation_name is None:\n",
    "    obs_label = 'Observations'\n",
    "  else:\n",
    "    obs_label = observation_name\n",
    "  match arg:\n",
    "    case 'default':\n",
    "      for i, model in enumerate(models):\n",
    "        print(model)\n",
    "        synthetic_runner.plotter(model)\n",
    "    case '2d':\n",
    "      if figsize is None:\n",
    "        size = (8,3)\n",
    "      else:\n",
    "        assert len(figsize) == 2 and isinstance(figsize, tuple), 'incorrect format for figure shape\\nshould be tuple of form (i,j)'\n",
    "        size = figsize\n",
    "      for i, model in enumerate(models):\n",
    "        fig = plt.figure(figsize=size)\n",
    "        axes = []\n",
    "        y_predict = model.predict(x_test)\n",
    "        for j in range(num_var):\n",
    "          axes.append(fig.add_subplot(1, num_var, j+1))\n",
    "          axes[j].set_xlabel(var_names[j])\n",
    "          axes[j].set_ylabel(obs_label)\n",
    "          axes[j].set_title(names[i]+' fit on '+var_names[j])\n",
    "          axes[j].scatter(x_test[:,j], y_test, label='Ground Truth', alpha=0.5)\n",
    "          axes[j].scatter(x_test[:,j], y_predict, label='Predicted', alpha=0.5)\n",
    "          axes[j].legend()\n",
    "          for arg in args:\n",
    "            assert isinstance(arg, str), 'arguments must be in the form of a string'\n",
    "            try:\n",
    "              exec('axes[j].'+arg)\n",
    "            except:\n",
    "              raise RuntimeError(f'argument \"{arg}\" could not be executed')\n",
    "\n",
    "      fig.tight_layout()\n",
    "      plt.show()\n",
    "    case '3d':\n",
    "      if figsize is None:\n",
    "        size = (15,5)\n",
    "      else:\n",
    "        assert len(figsize) == 2 and isinstance(figsize, tuple), 'incorrect format for figure shape\\nshould be tuple of form (i,j)'\n",
    "        size = figsize\n",
    "      axes = []\n",
    "      fig = plt.figure(figsize=size)\n",
    "      if select_indices is None:\n",
    "        idx = (0,1)\n",
    "      else:\n",
    "        len(select_indices) == 2 and isinstance(select_indices, tuple), 'incorrect format for select_indices\\nshould be tuple of form (i,j)'\n",
    "        idx = select_indices\n",
    "      for i, model in enumerate(models):\n",
    "        y_predict = model.predict(x_test)\n",
    "        ax = fig.add_subplot(1, 3, i+1, projection='3d')\n",
    "        ax.w_xaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "        ax.w_yaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "        ax.w_zaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "        axes.append(ax)\n",
    "        axes[i].set_xlabel(var_names[idx[0]])\n",
    "        axes[i].set_ylabel(var_names[idx[1]])\n",
    "        axes[i].set_zlabel(obs_label)\n",
    "        axes[i].scatter(x_test[:, idx[0]], x_test[:, idx[1]], y_test, s=1, label='Ground Truth')\n",
    "        axes[i].scatter(x_test[:, idx[0]], x_test[:, idx[1]], y_predict, s=1, label='Predicted')\n",
    "        axes[i].set_title(names[i])\n",
    "        axes[i].legend()\n",
    "        axes[i].set_facecolor('white')\n",
    "        for arg in args:\n",
    "            assert isinstance(arg, str), 'arguments must be in the form of a string'\n",
    "            try:\n",
    "              exec('axes[j].'+arg)\n",
    "            except:\n",
    "              raise RuntimeError(f'argument \"{arg}\" could not be executed')\n",
    "      fig.tight_layout()\n",
    "      plt.show()\n",
    "    case 'choice':\n",
    "      for model in models:\n",
    "        y_pred = np.where(model.predict(x_test) > 0.5, 1, 0)\n",
    "        cm = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "        cmd = ConfusionMatrixDisplay(cm)\n",
    "        cmd.plot()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Polynomial Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*make model* if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "class PolynomialRegressor:\n",
    "    \"\"\"\n",
    "    This theorist fits a polynomial function to the data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, degree: int = 3):\n",
    "      self.poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "      self.model = LinearRegression()\n",
    "\n",
    "    def fit(self, x, y):\n",
    "      features = self.poly.fit_transform(x, y)\n",
    "      self.model.fit(features, y)\n",
    "      return self\n",
    "\n",
    "    def predict(self, x):\n",
    "      features = self.poly.fit_transform(x)\n",
    "      return self.model.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "poly_model = PolynomialRegressor(degree=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Fit Model to the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_model.fit(conditions_train, observations_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Plot the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "present_results(model=poly_model, x_test=conditions_test, y_test=observations_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "present_results(model=poly_model, x_test=conditions_test, y_test=observations_test, arg='2d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "present_results(model=poly_model, x_test=conditions_test, y_test=observations_test, arg='3d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary - Polynomial Linear Regressor\n",
    "\n",
    "Expressivity: Low\n",
    "\n",
    "Interpretability: High"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Neural Network\n",
    "For this section, we are using torch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "import torch\n",
    "nn_model = MLPRegressor(random_state=1, max_iter=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Fit Model to the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "nn_model.fit(conditions_train, observations_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Plot the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_runner.plotter(nn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary - Neural Network Regressor\n",
    "\n",
    "Expressivity: High\n",
    "\n",
    "Interpretability: Low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bayesian Machine Scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bms_model = BMSRegressor(epochs=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Fit Model to Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bms_model.fit(conditions_train, observations_train, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Plot the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_runner.plotter(bms_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bms_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary - BMS Regressor\n",
    "\n",
    "Expressiveness: High\n",
    "\n",
    "Interpretability: High\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary - Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [poly_model, nn_model, bms_model]\n",
    "names =['poly_model', 'nn_model', 'bms_model']\n",
    "compare_results(models=models, x_test=conditions_test, y_test=observations_test, model_names=names, arg='2d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_results(models=models, x_test=conditions_test, y_test=observations_test, model_names=names, arg='3d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choice Model Recovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Import relevant modules from AutoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autora.experiment_runner.synthetic.psychology.luce_choice_ratio import luce_choice_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Import your data\n",
    "*(Here we create noisy synthetic data as a demonstration)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimental parameter to recover\n",
    "focus = 0.8\n",
    "\n",
    "# synthetic experiment from autora inventory\n",
    "synthetic_runner = luce_choice_ratio(focus=focus)\n",
    "\n",
    "# variables\n",
    "ivs = [iv.name for iv in synthetic_runner.variables.independent_variables]\n",
    "dvs = [dv.name for dv in synthetic_runner.variables.dependent_variables]\n",
    "\n",
    "\n",
    "# experimental data\n",
    "conditions = synthetic_runner.domain()\n",
    "experiment_data = synthetic_runner.run(conditions, added_noise=0.01)\n",
    "observations = experiment_data[dvs]\n",
    "\n",
    "# set probabilities to choice values\n",
    "observations = np.where(observations < 0.5, 0, 1)\n",
    "\n",
    "# split into train and test datasets\n",
    "conditions_train, conditions_test, observations_train, observations_test = train_test_split(conditions, observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Initialize Model\n",
    "5. Fit Model to the Data\n",
    "6. Plot the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Fit Model to the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model.fit(conditions_train, observations_train)\n",
    "# log_model.predict(conditions_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Plot the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "present_results(model=log_model, x_test=conditions_test, y_test=observations_test, arg='choice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary - Logisitic Regressor\n",
    "\n",
    "Expressiveness: Low\n",
    "\n",
    "Interpretability: Medium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nn_class_model = MLPClassifier(max_iter=3000, activation='logistic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Fit Model to the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_class_model.fit(conditions_train, observations_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Plot the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "present_results(model=nn_class_model, x_test=conditions_test, y_test=observations_test, arg='choice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary - Neural Network Regressor\n",
    "\n",
    "Expressiveness: High\n",
    "\n",
    "Interpretability: Low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Machine Scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bms_model = BMSRegressor(epochs=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Fit Model to the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bms_model.fit(conditions_train, observations_train, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Plot the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bms_model)\n",
    "present_results(model=bms_model, x_test=conditions_test, y_test=observations_test, arg='choice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary - BMS Regressor\n",
    "\n",
    "Expressiveness: High\n",
    "\n",
    "Interpretability: High\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary - Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "present_results(model=log_model, x_test=conditions_test, y_test=observations_test, arg='choice')\n",
    "present_results(model=nn_class_model, x_test=conditions_test, y_test=observations_test, arg='choice')\n",
    "present_results(model=bms_model, x_test=conditions_test, y_test=observations_test, arg='choice')\n",
    "print(bms_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FYI: AutoRA Toolkit Pre-release for integrating symbolic regression into any other modeling method of your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Try it yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install package that you will need here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages you will need here\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment the next lines and input the file location or replace with a line of your own\n",
    "# FILE_LOCATION = ''\n",
    "# df = pd.read_csv(FILE_LOCATION)\n",
    "\n",
    "## Extract your conditions and observations from your loaded data\n",
    "# conditions =\n",
    "# observations =\n",
    "\n",
    "## Run this line and make sure you train with the train datasets and test with the test datasets\n",
    "## This ensures that your model hasn't overfit\n",
    "# conditions_train, conditions_test, observations_train, observations_test = train_test_split(conditions, observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use BMS for this exercise. Feel free to initialize another model to compare it to\n",
    "# Minimum recommended number of epochs is 1500\n",
    "bms_model = BMSRegressor(epochs=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Fit model to the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment this next line after you have completed step 3\n",
    "# bms_model.fit(conditions_train, observations_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment this next line after you have completed step 5\n",
    "# plot_type = \"default\", \"2d\", \"3d\", or \"choice\"\n",
    "# present_results(bms_model, conditions_test, observations_test, arg=plot_type)\n",
    "\n",
    "## You can uncomment these lines if you would like to compare BMS to a model of your choice\n",
    "# your_models_name =\n",
    "# your_model =\n",
    "#\n",
    "# models = [bms_model, your_model]\n",
    "# model_names = [\"bms_model\", your_models_name]\n",
    "# compare results(models=models, x_test=conditions_test, y_test=observations_test, model_names=model_names, arg=plot_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Using the AutoRA closed loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://autoresearch.github.io/autora/tutorials/ for a tutorial on closed-loop experimentation.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
