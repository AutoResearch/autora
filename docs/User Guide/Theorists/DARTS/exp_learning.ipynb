{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Differentiable Architecture Search\n",
    "\n",
    "## Tutorial: Recovering the exponential learning curve model\n",
    "\n",
    "In this tutorial, we'll learn how to use Differentiable Architecture Search (DARTS) as a theorist to recover the exponential learning curve model.\n",
    "\n",
    "### Installing AutoRA\n",
    "\n",
    "We begin with installing AutoRA via the pip package manager, and then import the relevant modules:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autora in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (0.0.0)\r\n",
      "Requirement already satisfied: graphviz<0.21.0,>=0.14.1 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from autora) (0.20.1)\r\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.1.1 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from autora) (1.2.2)\r\n",
      "Requirement already satisfied: numpy>=1.22.1 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from autora) (1.24.2)\r\n",
      "Requirement already satisfied: seaborn<0.13.0,>=0.11.1 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from autora) (0.12.2)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.64.0 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from autora) (4.65.0)\r\n",
      "Requirement already satisfied: torch==2.0.0 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from autora) (2.0.0)\r\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.9.3 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from autora) (1.10.1)\r\n",
      "Requirement already satisfied: imageio<3.0.0,>=2.9.0 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from autora) (2.27.0)\r\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.2.1 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from autora) (3.7.1)\r\n",
      "Requirement already satisfied: sympy<2.0.0,>=1.10.1 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from autora) (1.11.1)\r\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.4.2 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from autora) (2.0.0)\r\n",
      "Requirement already satisfied: filelock in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from torch==2.0.0->autora) (3.10.7)\r\n",
      "Requirement already satisfied: jinja2 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from torch==2.0.0->autora) (3.1.2)\r\n",
      "Requirement already satisfied: networkx in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from torch==2.0.0->autora) (3.1)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from torch==2.0.0->autora) (4.5.0)\r\n",
      "Requirement already satisfied: pillow>=8.3.2 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from imageio<3.0.0,>=2.9.0->autora) (9.5.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from matplotlib<4.0.0,>=3.2.1->autora) (1.0.7)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from matplotlib<4.0.0,>=3.2.1->autora) (4.39.3)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from matplotlib<4.0.0,>=3.2.1->autora) (23.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from matplotlib<4.0.0,>=3.2.1->autora) (3.0.9)\r\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from matplotlib<4.0.0,>=3.2.1->autora) (5.12.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from matplotlib<4.0.0,>=3.2.1->autora) (2.8.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from matplotlib<4.0.0,>=3.2.1->autora) (0.11.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from matplotlib<4.0.0,>=3.2.1->autora) (1.4.4)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from pandas<3.0.0,>=1.4.2->autora) (2023.3)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from pandas<3.0.0,>=1.4.2->autora) (2023.3)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from scikit-learn<2.0.0,>=1.1.1->autora) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from scikit-learn<2.0.0,>=1.1.1->autora) (3.1.0)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from sympy<2.0.0,>=1.10.1->autora) (1.3.0)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib<4.0.0,>=3.2.1->autora) (3.15.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.2.1->autora) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/benwandrew/Library/Caches/pypoetry/virtualenvs/autora--WSX6yBF-py3.8/lib/python3.8/site-packages (from jinja2->torch==2.0.0->autora) (2.1.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install autora\n",
    "\n",
    "import numpy as np\n",
    "from autora.variable import DV, IV, ValueType, VariableCollection\n",
    "from autora.skl.darts import DARTSRegressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generating Data\n",
    "\n",
    "Next, we generate a relevant data set. We'll start by setting the relevant meta-parameter, which is the level of noise to add to the ground-truth model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# general meta parameters\n",
    "added_noise = 0.01"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we set the specific parameters for the exponential learning curve model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# exponential learning curve parameters\n",
    "exp_learning_resolution = 100\n",
    "exp_learning_minimum_trial = 1\n",
    "exp_learning_maximum_trial = exp_learning_resolution\n",
    "exp_learning_minimum_initial_value = 0\n",
    "exp_learning_maximum_initial_value = 0.5\n",
    "exp_learning_lr = 0.03\n",
    "exp_learning_p_asymptotic = 1.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then set up the ground-truth model. To do so, we first define our metadata"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def exp_learning_metadata():\n",
    "    p_initial = IV(\n",
    "        name=\"P_asymptotic\",\n",
    "        allowed_values=np.linspace(exp_learning_minimum_initial_value,\n",
    "                                   exp_learning_maximum_initial_value,\n",
    "                                   exp_learning_resolution),\n",
    "        value_range=(exp_learning_minimum_initial_value,\n",
    "                     exp_learning_maximum_initial_value),\n",
    "        units=\"performance\",\n",
    "        variable_label=\"Asymptotic Performance\",\n",
    "        type=ValueType.REAL\n",
    "    )\n",
    "\n",
    "    trial = IV(\n",
    "        name=\"trial\",\n",
    "        allowed_values=np.linspace(exp_learning_minimum_trial,\n",
    "                                   exp_learning_maximum_trial,\n",
    "                                   exp_learning_resolution),\n",
    "        value_range=(exp_learning_minimum_trial,\n",
    "                     exp_learning_maximum_trial),\n",
    "        units=\"trials\",\n",
    "        variable_label=\"Trials\",\n",
    "        type=ValueType.REAL\n",
    "    )\n",
    "\n",
    "    performance = DV(\n",
    "        name=\"performance\",\n",
    "        value_range=(0, exp_learning_p_asymptotic),\n",
    "        units=\"performance\",\n",
    "        variable_label=\"Performance\",\n",
    "        type=ValueType.REAL\n",
    "    )\n",
    "\n",
    "    metadata = VariableCollection(\n",
    "        independent_variables=[p_initial, trial],\n",
    "        dependent_variables=[performance],\n",
    "    )\n",
    "\n",
    "    return metadata"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we define our synthetic experiment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def exp_learning_experiment(X: np.ndarray,\n",
    "                             p_asymptotic: float = exp_learning_p_asymptotic,\n",
    "                             lr: float = exp_learning_lr,\n",
    "                             std = added_noise):\n",
    "    Y = np.zeros((X.shape[0],1))\n",
    "\n",
    "    for idx, x in enumerate(X):\n",
    "        p_initial = x[0]\n",
    "        trial = x[1]\n",
    "        y = p_asymptotic - (p_asymptotic - p_initial) * np.exp(- lr * trial) + np.random.normal(0, std)\n",
    "        Y[idx] = y\n",
    "\n",
    "    return Y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we define how to generate synthetic data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def exp_learning_data(metadata):\n",
    "\n",
    "    p_initial_values = metadata.independent_variables[0].allowed_values\n",
    "    trial_values = metadata.independent_variables[1].allowed_values\n",
    "\n",
    "    X = np.array(np.meshgrid(p_initial_values, trial_values)).T.reshape(-1,2)\n",
    "    y = exp_learning_experiment(X, std=0)\n",
    "\n",
    "    return X, y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With these functions defined, we can now create a data set from a noisy ground-truth model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "X, y = exp_learning_data(exp_learning_metadata())\n",
    "\n",
    "y = y.flatten()\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let us define the search space, that is, the space of operations to consider when searching over the space of computation graphs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "primitives = [\n",
    "    \"none\",\n",
    "    \"add\",\n",
    "    \"subtract\",\n",
    "    'mult',\n",
    "    \"logistic\",\n",
    "    'exp',\n",
    "    'relu',\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set up the DARTS Regressor\n",
    "\n",
    "We will use the DARTS Regressor to predict the outcomes. There are a number of parameters that determine how the architecture search is performed. The most important ones are listed below:\n",
    "\n",
    "- **num_graph_nodes**: The number of latent variables used to represent the model.\n",
    "- **arch_updates_per_epoch**: The number of architecture updates per training epoch. These updates affect the architecture weights $\\alpha$ indicating the relative contribution of each operation for a given computation step.\n",
    "- **arch_learning_rate_max**: The initial learning rate of the architecture weight optimizer.\n",
    "- **param_updates_per_epoch**: The number of parameter updates per epoch. Once the architecture updates are complete, the parameters associated with each operation are updated.\n",
    "- **param_momentum**: The momentum of the parameter optimizer.\n",
    "- **max_epochs**: The maximum number of epochs to run DARTS.\n",
    "- **output_type**: The type of output to produce. In our case, we treat the outcome as a real variable, i.e., \"real\".\n",
    "\n",
    "\n",
    "Let's set up the DARTS regressor with some default parameters.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "darts_estimator = DARTSRegressor(\n",
    "    num_graph_nodes=1,\n",
    "    arch_updates_per_epoch=1,\n",
    "    arch_learning_rate_max=0.001,\n",
    "    param_updates_per_epoch=500,\n",
    "    param_momentum=0.9,\n",
    "    max_epochs=300,\n",
    "    output_type=\"real\",\n",
    "    primitives=primitives,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we have everything to run differentiable architecture search and visualize the model resulting from the highest architecture weights. Note that the current model corresponds to the model with the highest architecture weights."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_1 = np.linspace(0, 1, num=10)\n",
    "x_2 = np.linspace(0, 1, num=10)\n",
    "X = np.array(np.meshgrid(x_1, x_2)).T.reshape(-1,2)\n",
    "\n",
    "y = 2 * X[:,0] + np.exp(5 * X[:,1])\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/300 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2195cb1ce064ae498fffa9722d5ddea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdarts_estimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/autora/autora/skl/darts.py:603\u001B[0m, in \u001B[0;36mDARTSRegressor.fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    597\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[1;32m    598\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClassification not implemented for DARTSRegressor.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    599\u001B[0m     )\n\u001B[1;32m    601\u001B[0m params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_params()\n\u001B[0;32m--> 603\u001B[0m fit_results \u001B[38;5;241m=\u001B[39m \u001B[43m_general_darts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnetwork\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnetwork_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    604\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mX_ \u001B[38;5;241m=\u001B[39m X\n\u001B[1;32m    605\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my_ \u001B[38;5;241m=\u001B[39m y\n",
      "File \u001B[0;32m~/Developer/autora/autora/skl/darts.py:193\u001B[0m, in \u001B[0;36m_general_darts\u001B[0;34m(X, y, network, batch_size, num_graph_nodes, output_type, classifier_weight_decay, darts_type, init_weights_function, param_updates_per_epoch, param_updates_for_sampled_model, param_learning_rate_max, param_learning_rate_min, param_momentum, param_weight_decay, arch_learning_rate_max, arch_updates_per_epoch, arch_weight_decay, arch_weight_decay_df, arch_weight_decay_base, arch_momentum, fair_darts_loss_weight, max_epochs, grad_clip, primitives, train_classifier_coefficients, train_classifier_bias, execution_monitor, sampling_strategy)\u001B[0m\n\u001B[1;32m    185\u001B[0m         architect\u001B[38;5;241m.\u001B[39mstep(\n\u001B[1;32m    186\u001B[0m             input_valid\u001B[38;5;241m=\u001B[39mX_batch,\n\u001B[1;32m    187\u001B[0m             target_valid\u001B[38;5;241m=\u001B[39my_batch,\n\u001B[1;32m    188\u001B[0m             network_optimizer\u001B[38;5;241m=\u001B[39marchitect\u001B[38;5;241m.\u001B[39moptimizer,\n\u001B[1;32m    189\u001B[0m             unrolled\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    190\u001B[0m         )\n\u001B[1;32m    192\u001B[0m     \u001B[38;5;66;03m# Then run the param optimization\u001B[39;00m\n\u001B[0;32m--> 193\u001B[0m     \u001B[43m_optimize_coefficients\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    194\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnetwork\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnetwork\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    195\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    196\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    197\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_clip\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_clip\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    198\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparam_learning_rate_max\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparam_learning_rate_max\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparam_learning_rate_min\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparam_learning_rate_min\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    200\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparam_momentum\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparam_momentum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    201\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparam_update_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparam_updates_per_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    202\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparam_weight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparam_weight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    203\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    205\u001B[0m     execution_monitor(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mlocals\u001B[39m())\n\u001B[1;32m    207\u001B[0m model \u001B[38;5;241m=\u001B[39m _generate_model(\n\u001B[1;32m    208\u001B[0m     network_\u001B[38;5;241m=\u001B[39mnetwork,\n\u001B[1;32m    209\u001B[0m     output_type\u001B[38;5;241m=\u001B[39moutput_type,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    217\u001B[0m     grad_clip\u001B[38;5;241m=\u001B[39mgrad_clip,\n\u001B[1;32m    218\u001B[0m )\n",
      "File \u001B[0;32m~/Developer/autora/autora/skl/darts.py:268\u001B[0m, in \u001B[0;36m_optimize_coefficients\u001B[0;34m(network, criterion, data_loader, grad_clip, param_learning_rate_max, param_learning_rate_min, param_momentum, param_update_steps, param_weight_decay)\u001B[0m\n\u001B[1;32m    264\u001B[0m data_iterator \u001B[38;5;241m=\u001B[39m _get_data_iterator(data_loader)\n\u001B[1;32m    266\u001B[0m objs \u001B[38;5;241m=\u001B[39m AvgrageMeter()\n\u001B[0;32m--> 268\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mnetwork\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcount_parameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    269\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m    271\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m param_step \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(param_update_steps):\n",
      "File \u001B[0;32m~/Developer/autora/autora/theorist/darts/model_search.py:615\u001B[0m, in \u001B[0;36mNetwork.count_parameters\u001B[0;34m(self, print_parameters)\u001B[0m\n\u001B[1;32m    612\u001B[0m maxIdx \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mwhere(values \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mmax\u001B[39m(values))\n\u001B[1;32m    614\u001B[0m tmp_param_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m()\n\u001B[0;32m--> 615\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m isiterable(op\u001B[38;5;241m.\u001B[39m_ops[\u001B[43mmaxIdx\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m]):  \u001B[38;5;66;03m# Zero is not iterable\u001B[39;00m\n\u001B[1;32m    617\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m subop \u001B[38;5;129;01min\u001B[39;00m op\u001B[38;5;241m.\u001B[39m_ops[maxIdx[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mitem(\u001B[38;5;241m0\u001B[39m)]:\n\u001B[1;32m    619\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m parameter \u001B[38;5;129;01min\u001B[39;00m subop\u001B[38;5;241m.\u001B[39mparameters():\n",
      "\u001B[0;31mIndexError\u001B[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "darts_estimator.fit(X, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can refine the fit by running the `fit` method again, after changing the parameters. This allows us to keep the same architecture but refit the parameters in the final sampled model, for example:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'darts_estimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdarts_estimator\u001B[49m\u001B[38;5;241m.\u001B[39mset_params(\n\u001B[1;32m      2\u001B[0m     max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,  \u001B[38;5;66;03m# no epochs of architecture fitting\u001B[39;00m\n\u001B[1;32m      3\u001B[0m     param_updates_for_sampled_model\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m,  \u001B[38;5;66;03m# 1000 steps of param optimiziation\u001B[39;00m\n\u001B[1;32m      4\u001B[0m )\n\u001B[1;32m      5\u001B[0m darts_estimator\u001B[38;5;241m.\u001B[39mfit(X, y)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'darts_estimator' is not defined"
     ]
    }
   ],
   "source": [
    "darts_estimator.set_params(\n",
    "    max_epochs=0,  # no epochs of architecture fitting\n",
    "    param_updates_for_sampled_model=1000,  # 1000 steps of param optimiziation\n",
    ")\n",
    "darts_estimator.fit(X, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also change how the model is sampled from the architecture weight distribution:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "darts_estimator.set_params(\n",
    "    max_epochs=0,  # no epochs of architecture fitting\n",
    "    sampling_strategy=\"sample\",  # overriding default \"max\"\n",
    "    param_updates_for_sampled_model=800,\n",
    ")\n",
    "darts_estimator.fit(X, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To recover the initial model, we need to return the sampling strategy to the default `\"max\"`:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'darts_estimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdarts_estimator\u001B[49m\u001B[38;5;241m.\u001B[39mset_params(\n\u001B[1;32m      2\u001B[0m     max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,  \u001B[38;5;66;03m# no epochs of architecture fitting\u001B[39;00m\n\u001B[1;32m      3\u001B[0m     sampling_strategy\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      4\u001B[0m     param_updates_for_sampled_model\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m,\n\u001B[1;32m      5\u001B[0m )\n\u001B[1;32m      6\u001B[0m darts_estimator\u001B[38;5;241m.\u001B[39mfit(X, y)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'darts_estimator' is not defined"
     ]
    }
   ],
   "source": [
    "darts_estimator.set_params(\n",
    "    max_epochs=0,  # no epochs of architecture fitting\n",
    "    sampling_strategy=\"max\",\n",
    "    param_updates_for_sampled_model=1000,\n",
    ")\n",
    "darts_estimator.fit(X, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As long as the architecture has not been refitted in the meantime, the architecture should be identical to the initial result, as the `sampling_strategy=\"max\"` is deterministic. The coefficients of the architecture functions may, however, be different, as they have different starting values compared to when they were initially set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have both our ground-truth and the DARTS candidate models, we can plot them and compare results. We define how to create our plot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_exp_learning(model = None):\n",
    "    plot_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    metadata = exp_learning_metadata()\n",
    "\n",
    "    P_0_list = [0, 0.25, 0.5]\n",
    "    trial = metadata.independent_variables[1].allowed_values\n",
    "\n",
    "    for P_0_index, P_0 in enumerate(P_0_list):\n",
    "        X = np.zeros((len(trial), 2))\n",
    "        X[:, 0] = P_0\n",
    "        X[:, 1] = trial\n",
    "\n",
    "        y = exp_learning_experiment(X, std=0)\n",
    "        plt.plot(trial, y, label=f\"$P_0 = {P_0}$ (Original)\", color = plot_colors[P_0_index])\n",
    "        if model is not None:\n",
    "            y = model.predict(X)\n",
    "            plt.plot(trial, y, label=f\"$P_0 = {P_0}$ (Recovered)\", linestyle=\"--\", color = plot_colors[P_0_index])\n",
    "\n",
    "    x_limit = [0, metadata.independent_variables[1].value_range[1]]\n",
    "    y_limit = [0, 1]\n",
    "    x_label = \"Trial $t$\"\n",
    "    y_label = \"Performance $P_n$\"\n",
    "\n",
    "    plt.xlim(x_limit)\n",
    "    plt.ylim(y_limit)\n",
    "    plt.xlabel(x_label, fontsize=\"large\")\n",
    "    plt.ylabel(y_label, fontsize=\"large\")\n",
    "    plt.legend(loc=4, fontsize=\"medium\")\n",
    "    plt.title(\"Exponential Learning\", fontsize=\"x-large\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And then we pass in our new DARTS candidate model to get our visual comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_exp_learning(darts_estimator)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
