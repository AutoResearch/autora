{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Bayesian Symbolic Regression\n",
    "\n",
    "## Tutorial: Recovering the exponential learning curve model\n",
    "\n",
    "In this tutorial, we'll learn how to use Bayesian Symbolic Regression (BSR) as a theorist to recover the exponential learning curve model.\n",
    "\n",
    "### Installing AutoRA\n",
    "\n",
    "We begin with installing AutoRA via the pip package manager, and then import the relevant modules:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "!pip install autora\n",
    "\n",
    "import numpy as np\n",
    "from autora.variable import DV, IV, ValueType, VariableCollection\n",
    "from autora.skl.bsr import BSRRegressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generating Data\n",
    "\n",
    "Next, we generate a relevant data set. We'll start by setting the relevant meta-parameter, which is the level of noise to add to the ground-truth model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# general meta parameters\n",
    "added_noise = 0.01"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we set the specific parameters for the exponential learning curve model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# exponential learning curve parameters\n",
    "exp_learning_resolution = 100\n",
    "exp_learning_minimum_trial = 1\n",
    "exp_learning_maximum_trial = exp_learning_resolution\n",
    "exp_learning_minimum_initial_value = 0\n",
    "exp_learning_maximum_initial_value = 0.5\n",
    "exp_learning_lr = 0.03\n",
    "exp_learning_p_asymptotic = 1.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then set up the ground-truth model. To do so, we first define our metadata"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def exp_learning_metadata():\n",
    "    p_initial = IV(\n",
    "        name=\"P_asymptotic\",\n",
    "        allowed_values=np.linspace(exp_learning_minimum_initial_value,\n",
    "                                   exp_learning_maximum_initial_value,\n",
    "                                   exp_learning_resolution),\n",
    "        value_range=(exp_learning_minimum_initial_value,\n",
    "                     exp_learning_maximum_initial_value),\n",
    "        units=\"performance\",\n",
    "        variable_label=\"Asymptotic Performance\",\n",
    "        type=ValueType.REAL\n",
    "    )\n",
    "\n",
    "    trial = IV(\n",
    "        name=\"trial\",\n",
    "        allowed_values=np.linspace(exp_learning_minimum_trial,\n",
    "                                   exp_learning_maximum_trial,\n",
    "                                   exp_learning_resolution),\n",
    "        value_range=(exp_learning_minimum_trial,\n",
    "                     exp_learning_maximum_trial),\n",
    "        units=\"trials\",\n",
    "        variable_label=\"Trials\",\n",
    "        type=ValueType.REAL\n",
    "    )\n",
    "\n",
    "    performance = DV(\n",
    "        name=\"performance\",\n",
    "        value_range=(0, exp_learning_p_asymptotic),\n",
    "        units=\"performance\",\n",
    "        variable_label=\"Performance\",\n",
    "        type=ValueType.REAL\n",
    "    )\n",
    "\n",
    "    metadata = VariableCollection(\n",
    "        independent_variables=[p_initial, trial],\n",
    "        dependent_variables=[performance],\n",
    "    )\n",
    "\n",
    "    return metadata"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we define our synthetic experiment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def exp_learning_experiment(X: np.ndarray,\n",
    "                             p_asymptotic: float = exp_learning_p_asymptotic,\n",
    "                             lr: float = exp_learning_lr,\n",
    "                             std = added_noise):\n",
    "    Y = np.zeros((X.shape[0],1))\n",
    "\n",
    "    for idx, x in enumerate(X):\n",
    "        p_initial = x[0]\n",
    "        trial = x[1]\n",
    "        y = p_asymptotic - (p_asymptotic - p_initial) * np.exp(- lr * trial) + np.random.normal(0, std)\n",
    "        Y[idx] = y\n",
    "\n",
    "    return Y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we define how to generate synthetic data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def exp_learning_data(metadata):\n",
    "\n",
    "    p_initial_values = metadata.independent_variables[0].allowed_values\n",
    "    trial_values = metadata.independent_variables[1].allowed_values\n",
    "\n",
    "    X = np.array(np.meshgrid(p_initial_values, trial_values)).T.reshape(-1,2)\n",
    "    y = exp_learning_experiment(X, std=0)\n",
    "\n",
    "    return X, y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With these functions defined, we can now create a data set from a noisy ground-truth model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "X, y = exp_learning_data(exp_learning_metadata())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let us define the search space, that is, the space of operations to consider when searching over the space of computation graphs. BSR comes with the following built-in operations:\n",
    "\n",
    "- **\\+**: The output of the computation $x_j$ is the sum over its inputs $x_i, x_{ii}$: $x_j = x_i + x_{ii}$.\n",
    "- **\\-**: The output of the computation $x_j$ is the respective difference between its inputs $x_i, x_{ii}$: $x_j = x_i - x_{ii}$.\n",
    "- __\\*__: The output of the computation $x_j$ is the product over its two inputs $x_i, x_{ii}$: $x_j = x_i * x_{ii}$.\n",
    "- **exp**: The output of the computation $x_j$ is the natural exponential function applied to its input $x_i$: $x_j = \\exp(x_i)$.\n",
    "- **pow2**: The output of the computation $x_j$ is the square function applied to its input $x_i$: $x_j$ = $x_i^2$.\n",
    "- **pow3**: The output of the computation $x_j$ is the cube function applied to its input $x_i$: $x_j$ = $x_i^3$.\n",
    "- **sin**: The output of the computation $x_j$ is the sine function applied to its input $x_i$: $x_j = \\sin(x_i)$.\n",
    "- **cos**: The output of the computation $x_j$ is the cosine function applied to its input $x_i$: $x_j = \\cos(x_i)$.\n",
    "- **ln**: The output of the computation $x_j$ is the linear transformation applied to its input $x_i$: $x_j = a * x_i + b$, where $a$ and $b$ are slope and intercept parameters.\n",
    "\n",
    "The meta-parameters for BSR have default settings, which we will use for this example. Those defaults are as follows:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "bsr_estimator = BSRRegressor(\n",
    "    tree_num=3,\n",
    "    itr_num=1000,\n",
    "    val=100,\n",
    "    beta=-1,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With regressor created and all its meta-parameters assigned, we can now fit the regressor to our synthetic data set. That is, we can use the BSRRegressor to recover an equation that it thinks best maps X to y."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "bsr_estimator.fit(X,y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have both our ground-truth and the BSR candidate models, we can plot them and compare results. We define how to create our plot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def plot_exp_learning(model = None):\n",
    "    plot_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    metadata = exp_learning_metadata()\n",
    "\n",
    "    P_0_list = [0, 0.25, 0.5]\n",
    "    trial = metadata.independent_variables[1].allowed_values\n",
    "\n",
    "    for P_0_index, P_0 in enumerate(P_0_list):\n",
    "        X = np.zeros((len(trial), 2))\n",
    "        X[:, 0] = P_0\n",
    "        X[:, 1] = trial\n",
    "\n",
    "        y = exp_learning_experiment(X, std=0)\n",
    "        plt.plot(trial, y, label=f\"$P_0 = {P_0}$ (Original)\", color = plot_colors[P_0_index])\n",
    "        if model is not None:\n",
    "            y = model.predict(X)\n",
    "            plt.plot(trial, y, label=f\"$P_0 = {P_0}$ (Recovered)\", linestyle=\"--\", color = plot_colors[P_0_index])\n",
    "\n",
    "    x_limit = [0, metadata.independent_variables[1].value_range[1]]\n",
    "    y_limit = [0, 1]\n",
    "    x_label = \"Trial $t$\"\n",
    "    y_label = \"Performance $P_n$\"\n",
    "\n",
    "    plt.xlim(x_limit)\n",
    "    plt.ylim(y_limit)\n",
    "    plt.xlabel(x_label, fontsize=\"large\")\n",
    "    plt.ylabel(y_label, fontsize=\"large\")\n",
    "    plt.legend(loc=4, fontsize=\"medium\")\n",
    "    plt.title(\"Exponential Learning\", fontsize=\"x-large\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And then we pass in our new BSR candidate model to get our visual comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "plot_exp_learning(bsr_estimator)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
