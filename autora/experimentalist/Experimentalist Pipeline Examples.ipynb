{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from functools import partial\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from autora.variable import DV, IV, ValueType, VariableCollection\n",
    "from autora.experimentalist.pipeline import PoolPipeline\n",
    "from autora.experimentalist.pool import gridsearch_pool\n",
    "from autora.experimentalist.filter import weber_filter\n",
    "from autora.experimentalist.sampler import random_sampler, uncertainty_sampler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction\n",
    "This notebook demonstrates the use of the `PoolPipeline` class to create Experimentalists. Experimentalists consist of two main components:\n",
    "1. Condition Generation - Creating combinations of independent variables to test\n",
    "2. Experimental Design - Ensuring conditions meet design constraints.\n",
    "\n",
    "The `PoolPipeline` class allows us to define a series of functions to generate and process a pool of conditions that conform to an experimental design.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implementation\n",
    "\n",
    "The `PoolPipeline` class consists of two types of inputs:\n",
    "1. Pool - A pool of conditions or a function to generate it.\n",
    "2. Pipes - An arbitrary number of filter functions to apply to the pool.\n",
    "    * Examples of pipes may be samplers, conditional filters, and sequencers.\n",
    "\n",
    "<blockquote>\n",
    "\n",
    "```Python\n",
    "# Initialize the Pipeline\n",
    "pipeline = PoolPipeline(Pool, *Pipes)\n",
    "\n",
    "# Run the pipeline\n",
    "conditions = pipline.run()\n",
    "```\n",
    "</blockquote>\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example 1: Exhaustive Pool with Random Sampler\n",
    "The examples in this notebook will create a Weber line-lengths experiment. The Weber experiment tests human detection of differences between the lengths of two lines. The first example will sample a pool with simple random sampling. We will first define the independent and dependent variables (IVs and DVs, respectively).\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Specifying  Dependent and Independent Variables\n",
    "# Specify independent variables\n",
    "iv1 = IV(\n",
    "    name=\"S1\",\n",
    "    allowed_values=np.linspace(0, 5, 5),\n",
    "    units=\"intensity\",\n",
    "    variable_label=\"Stimulus 1 Intensity\",\n",
    ")\n",
    "\n",
    "iv2 = IV(\n",
    "    name=\"S2\",\n",
    "    allowed_values=np.linspace(0, 5, 5),\n",
    "    units=\"intensity\",\n",
    "    variable_label=\"Stimulus 2 Intensity\",\n",
    ")\n",
    "\n",
    "# The experimentalist pipeline doesn't actually use DVs, they are just specified here for\n",
    "# example.\n",
    "dv1 = DV(\n",
    "    name=\"difference_detected\",\n",
    "    value_range=(0, 1),\n",
    "    units=\"probability\",\n",
    "    variable_label=\"P(difference detected)\",\n",
    "    type=ValueType.PROBABILITY,\n",
    ")\n",
    "\n",
    "# Variable collection with ivs and dvs\n",
    "metadata = VariableCollection(\n",
    "    independent_variables=[iv1, iv2],\n",
    "    dependent_variables=[dv1],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we set up the `PoolPipeline` with three functions:\n",
    "1. `gridsearch_pool` - Generates an exhaustive pool of condition combinations using the Cartesian product of discrete IV values.\n",
    "   - The discrete IV values are specified with the `allowed_values` attribute when defining the IVs.\n",
    "2. `weber_filer` - Filter that selects the experimental design constraint where IV1 <= IV2.\n",
    "3. `random_sampler` - Samples the pool of conditions\n",
    "\n",
    "Functions that require keyword inputs are initialized using the `partial` function before passing into `PoolPipeline`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "## Set up pipeline functions with the partial function\n",
    "# Pool Function\n",
    "pooler_callable = partial(gridsearch_pool, ivs=metadata.independent_variables)\n",
    "# Random Sampler\n",
    "sampler = partial(random_sampler, n=10)\n",
    "\n",
    "# Initialize the pipeline\n",
    "pipeline_random_samp = PoolPipeline(\n",
    "    pooler_callable,\n",
    "    weber_filter, # Filter that selects conditions with IV1 <= IV2\n",
    "    sampler,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The pipleine can be run by calling the `run` method.\n",
    "\n",
    "The pipeline is run twice below to illustrate that random sampling is performed. Rerunning the cell will produce different results.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled Conditions:\n",
      " Run 1: [(0.0, 0.0), (0.0, 1.25), (0.0, 2.5), (0.0, 3.75), (1.25, 5.0), (1.25, 2.5), (1.25, 1.25), (3.75, 5.0), (2.5, 2.5), (5.0, 5.0)]\n",
      " Run 2: [(2.5, 5.0), (0.0, 0.0), (1.25, 5.0), (0.0, 2.5), (0.0, 3.75), (1.25, 1.25), (2.5, 3.75), (0.0, 1.25), (3.75, 5.0), (0.0, 5.0)]\n"
     ]
    }
   ],
   "source": [
    "# Run the Pipeline\n",
    "results1 = pipeline_random_samp.run()\n",
    "results2 = pipeline_random_samp.run()\n",
    "print('Sampled Conditions:')\n",
    "print(f' Run 1: {results1}\\n',\n",
    "      f'Run 2: {results2}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "An alternative method of passing an instantiated pool iterator is demonstrated below. Note the difference where `gridsearch_pool` is not initialized using the `partial` function but instantiated before initializing the `PoolPipeline`. `gridsearch_pool` returns an iterator of the exhaustive pool. This will result in unexpected behavior when the pipeline is run multiple times."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled Conditions:\n",
      " Run 1: [(2.5, 3.75), (3.75, 3.75), (1.25, 1.25), (1.25, 3.75), (0.0, 5.0), (3.75, 5.0), (0.0, 3.75), (5.0, 5.0), (1.25, 2.5), (1.25, 5.0)]\n",
      " Run 2: []\n"
     ]
    }
   ],
   "source": [
    "## Set up pipeline functions with the partial function\n",
    "# Pool Function\n",
    "pooler_iterator = gridsearch_pool(metadata.independent_variables)\n",
    "\n",
    "# Initialize the pipeline\n",
    "pipeline_random_samp2 = PoolPipeline(\n",
    "    pooler_iterator,\n",
    "    weber_filter, # Filter that selects conditions with IV1 <= IV2\n",
    "    sampler, # Sampler defined in the first implementation example\n",
    ")\n",
    "# Run the Pipeline\n",
    "results1 = pipeline_random_samp2.run()\n",
    "results2 = pipeline_random_samp2.run()\n",
    "print('Sampled Conditions:')\n",
    "print(f' Run 1: {results1}\\n',\n",
    "      f'Run 2: {results2}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Running the pipeline multiple times results in an empty list. This is because the iterator is exhausted after first run and no longer yields results. If the pipeline needs to be run multiple times, initializing the functions as a callable using the `partial` function is recommended because the iterator will be initialized at the start of each run.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example 2: Exhaustive Pool with Uncertainty Sampler\n",
    "The next example will sample a pool with uncertainty sampling. Uncertainty sampling requires a model that returns probabilities of class predictions. We will use synthetic data from a Weber experiment to train a simple logistic regression model.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression()",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "datafile_path = pathlib.Path(os.path.abspath(\"\")).parent.parent.joinpath(\"example/sklearn/darts/weber_data.csv\")\n",
    "data = pd.read_csv(datafile_path)\n",
    "X = data[[\"S1\", \"S2\"]]\n",
    "y = data[\"difference_detected\"] # Probability that a difference is detected\n",
    "y_classified = np.where(y >= .5, 1, 0)\n",
    "\n",
    "# Train logistic regression model\n",
    "logireg_model = LogisticRegression()\n",
    "logireg_model.fit(X, y_classified)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implementation is the same as Example 1 however we change the sampling function. The `uncertainty_sampler` is passed the logistic regression model and additional keywords specify to sample 10 conditions with using the 'least_confident' measure method. The uncertainty sampler uses the package [alipy QueryInstanceUncertainty](http://parnec.nuaa.edu.cn/_upload/tpl/02/db/731/template731/pages/huangsj/alipy/page_reference/api_classes/api_query_strategy.query_labels.QueryInstanceUncertainty.html) class to select for samples with the greatest uncertainty."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Set up pipeline functions with the partial function\n",
    "# Pool Function\n",
    "pooler_callable = partial(gridsearch_pool, ivs=metadata.independent_variables)\n",
    "# Uncertainty Sampler\n",
    "sampler = partial(uncertainty_sampler, model=logireg_model, n=10, measure='least_confident')\n",
    "\n",
    "# Initialize pipeline\n",
    "pipeline_uncertainty_samp = PoolPipeline(\n",
    "    pooler_callable,\n",
    "    weber_filter, # Filter that selects conditions with IV1 <= IV2\n",
    "    sampler,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled Conditions:\n",
      "[[1.25 5.  ]\n",
      " [3.75 5.  ]\n",
      " [2.5  2.5 ]\n",
      " [0.   1.25]\n",
      " [1.25 3.75]\n",
      " [2.5  3.75]\n",
      " [1.25 1.25]\n",
      " [0.   0.  ]\n",
      " [1.25 2.5 ]\n",
      " [2.5  5.  ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gdang2/repos/autora/.venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Run the Pipeline\n",
    "results1 = pipeline_uncertainty_samp.run()\n",
    "print('Sampled Conditions:')\n",
    "print(results1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Writing custom functions\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}