{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ba2ff78",
   "metadata": {},
   "source": [
    "Example file which shows some simple curve fitting using BMSRegressor and some other estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b221c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import warnings\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append('../')\n",
    "from aer_bms.skl.bms import BMSRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343e2f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results_complete(\n",
    "    data_: pd.DataFrame,\n",
    "    estimator=None,\n",
    "    show_results=True,\n",
    "    projection=\"2d\",\n",
    "    label=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Function to plot input data (x_, y_) and the predictions of an estimator for the same x_.\n",
    "    \"\"\"\n",
    "    if projection == \"2d\":\n",
    "        plt.figure()\n",
    "        data_.plot.scatter(\n",
    "            \"S1\", \"S2\", c=\"difference_detected\", cmap=\"viridis\", zorder=10\n",
    "        )\n",
    "    elif projection == \"3d\":\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(projection=\"3d\")\n",
    "        ax.scatter(data_[\"S1\"], data[\"S2\"], data[\"difference_detected\"])\n",
    "        if estimator is not None:\n",
    "            xs, ys = np.mgrid[0:5:0.2, 0:5:0.2]  # type: ignore\n",
    "            zs = estimator.predict(np.column_stack((xs.ravel(), ys.ravel())))\n",
    "            ax.plot_surface(xs, ys, zs.reshape(xs.shape), alpha=0.5)\n",
    "\n",
    "    if label is not None:\n",
    "        plt.title(label)\n",
    "\n",
    "    if show_results:\n",
    "        plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfd6747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "XLABS = [\n",
    "    \"S1\",\n",
    "    \"S2\",\n",
    "]\n",
    "data = pd.read_csv(\"../example/experiment_0_data.csv\")\n",
    "show_results = partial(show_results_complete, data_= data, projection=\"3d\")\n",
    "show_results(label=\"input data\")\n",
    "\n",
    "X, y = data[XLABS], data[\"difference_detected\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb47b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89405909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Fit first using a super-simple linear regression\n",
    "\n",
    "first_order_linear_estimator = LinearRegression()\n",
    "first_order_linear_estimator.fit(X, y)\n",
    "\n",
    "show_results(estimator=first_order_linear_estimator, label=\"1st order linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67dbeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Fit using a 0-3 order polynomial, getting the best fit for the data.\n",
    "polynomial_estimator = GridSearchCV(\n",
    "    make_pipeline(PolynomialFeatures(), LinearRegression(fit_intercept=False)),\n",
    "    param_grid=dict(polynomialfeatures__degree=range(4)),\n",
    ")\n",
    "polynomial_estimator.fit(X, y)\n",
    "\n",
    "show_results(estimator=polynomial_estimator, label=\"[0th-3rd]-order linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d870dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "# hyper parameters\n",
    "\n",
    "prior_par = {\n",
    "    \"Nopi_/\": 5.912205942815285,\n",
    "    \"Nopi_cosh\": 8.12720511103694,\n",
    "    \"Nopi_-\": 3.350846072163632,\n",
    "    \"Nopi_sin\": 5.965917796154835,\n",
    "    \"Nopi_tan\": 8.127427922862411,\n",
    "    \"Nopi_tanh\": 7.799259068142255,\n",
    "    \"Nopi_**\": 6.4734429542245495,\n",
    "    \"Nopi_pow2\": 3.3017352779079734,\n",
    "    \"Nopi_pow3\": 5.9907496760026175,\n",
    "    \"Nopi_exp\": 4.768665265735502,\n",
    "    \"Nopi_log\": 4.745957377206544,\n",
    "    \"Nopi_sqrt\": 4.760686909134266,\n",
    "    \"Nopi_cos\": 5.452564657261127,\n",
    "    \"Nopi_sinh\": 7.955723540761046,\n",
    "    \"Nopi_abs\": 6.333544134938385,\n",
    "    \"Nopi_+\": 5.808163661224514,\n",
    "    \"Nopi_*\": 5.002213595420244,\n",
    "    \"Nopi_fac\": 10.0,\n",
    "    \"Nopi2_*\": 1.0,\n",
    "}\n",
    "\n",
    "# temperatures\n",
    "ts = [1.0] + [1.04**k for k in range(1, 20)]\n",
    "\n",
    "# epoch num\n",
    "epochs = 100\n",
    "\n",
    "# fit model\n",
    "estimator = BMSRegressor(prior_par, ts, epochs)\n",
    "estimator = estimator.fit(X, y)\n",
    "\n",
    "# model estimate\n",
    "show_results(\n",
    "    estimator=estimator, label=\"BMS Regressor\"\n",
    ")\n",
    "print(estimator.model_)\n",
    "\n",
    "# model prediction\n",
    "test_x = X.head()\n",
    "estimator.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375b5b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.present_results()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
